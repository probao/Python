###################################
###numpy基础：数组和矢量的计算#####
###################################


创建ndarray
>>> import numpy as np
>>> data1 = [6, 7.5, 8, 0, 1]
>>> arr1 = np.array(data1)	# 使用array函数，它接受一切序列型的对象，产生一个含有传入数据的numpy数组
>>> arr1
array([ 6. ,  7.5,  8. ,  0. ,  1. ])


嵌套序列
>>> data2 = [[1,2,3,4], [5, 6, 7, 8]]
>>> arr2 = np.array(data2)
>>> arr2
array([[1, 2, 3, 4],
       [5, 6, 7, 8]])
>>> arr2.ndim	# 数组的维数
2
>>> arr2.shape	# 2行4列的数组
(2, 4)

>>> arr1.dtype	# 数据类型保存在一个特殊的dtype对象中
dtype('float64')
>>> arr2.dtype
dtype('int32')


其它函数新建数组
>>> np.zeros(10)	# 生成全是0的数组
array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
>>> np.zeros((3, 6))
array([[ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.]])
>>> np.ones((3, 6))	# 生成全是1的数组
array([[ 1.,  1.,  1.,  1.,  1.,  1.],
       [ 1.,  1.,  1.,  1.,  1.,  1.],
       [ 1.,  1.,  1.,  1.,  1.,  1.]])
>>> np.empty((2, 3, 2))		# 生成的不是0， 是一些未被处理的垃圾值
array([[[  1.03510883e-295,   6.38742701e-314],
        [  1.55420853e-285,   1.27319747e-313],
        [  1.27319747e-313,   1.27319747e-313]],

       [[  2.37332014e-286,   1.91205622e-313],
        [  8.13462439e-296,   2.75859453e-313],
        [  2.48324480e-286,   3.12237178e-120]]])

>>> np.arange(15)		# arange是python内置函数range的数组版
array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])

>>> np.eye(3)			# 对角线是1的数组
array([[ 1.,  0.,  0.],
       [ 0.,  1.,  0.],
       [ 0.,  0.,  1.]])


ndarray的数据类型
>>> arr1 = np.array([1, 2, 3], dtype=np.float64)
>>> arr2 = np.array([1, 2, 3], dtype=np.int32)
>>> arr1.dtype
dtype('float64')
>>> arr2.dtype
dtype('int32')



数组和标量之间的运算
>>> arr = np.array([[1., 2., 3.], [4., 5., 6.]])
>>> arr
array([[ 1.,  2.,  3.],
       [ 4.,  5.,  6.]])
>>> arr*arr
array([[  1.,   4.,   9.],	#大小相等的数组的任何运算都会将运算运用到元素级
       [ 16.,  25.,  36.]])
>>> 1/arr
array([[ 1.        ,  0.5       ,  0.33333333],
       [ 0.25      ,  0.2       ,  0.16666667]])
>>> arr**0.5
array([[ 1.        ,  1.41421356,  1.73205081],
       [ 2.        ,  2.23606798,  2.44948974]])

>>> a = np.array([[1,2],[1,2]])	#矩阵的运算需要dot函数
>>> np.dot(a,a)
array([[3, 6],
       [3, 6]])


基本的索引和切片
>>> import numpy as np
>>> arr = np.arange(10)
>>> arr
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>>
>>>
>>> arr[5]
5
>>>
>>> arr[5:8]
array([5, 6, 7])
>>> arr[5:8] = 12
>>> arr
array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9]) # 当一个标量值赋值给一个切片时，该值会自动传播到整个选取


>>> arr_slice = arr[5:8]
>>> arr_slice[1] = 12345
>>> arr
array([    0,     1,     2,     3,     4,    12, 12345,    12,     8,     9])
>>> arr_slice[:] = 64
>>> arr
array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])


>>> arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])	# 多维数组索引
>>> arr2d[2]
array([7, 8, 9])
>>> arr2d[0][2]
3
>>> arr2d[0, 2]
3


>>> arr3d = np.array([[[1, 2, 3], [4, 5, 6]],[[7, 8, 9], [10, 11, 12]]])
>>> arr3d	# 括号外面的“维度”是一维，二维，。。。而括号里面的应该理解为“轴”--类比三维数组
array([[[ 1,  2,  3],
        [ 4,  5,  6]],

       [[ 7,  8,  9],
        [10, 11, 12]]])
>>> arr3d [0]
array([[1, 2, 3],
       [4, 5, 6]])



>>> old_values = arr3d[0].copy()
>>>
>>> arr3d[0] = 42
>>> arr3d
array([[[42, 42, 42],
        [42, 42, 42]],

       [[ 7,  8,  9],
        [10, 11, 12]]])
>>> arr3d[0] = old_values	# 标量和数组都可以被赋值给arr3d[0]
>>> arr3d
array([[[ 1,  2,  3],
        [ 4,  5,  6]],

       [[ 7,  8,  9],
        [10, 11, 12]]])

>>> arr3d[1, 0]
array([7, 8, 9])

切片索引

>>> arr
array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])
>>> arr[1:6]
array([ 1,  2,  3,  4, 64])


>>> arr2d
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
>>> arr2d[:2]	#[:2]意思是--第0项和第1项
array([[1, 2, 3],
       [4, 5, 6]])
>>> arr2d[:2, 1:]	# [1:] 第一项到最后
array([[2, 3],
       [5, 6]])


>>> arr2d[1, :2]
array([4, 5])
>>> arr2d[2, :1]
array([7])
>>> arr2d[:, :1]	
array([[1],
       [4],
       [7]])
>>> arr2d[:2, 1:]
array([[2, 3],
       [5, 6]])
>>> arr2d[:2, 1:] = 0	#对切片表达式的赋值操作也会被扩赛到整个选区
>>> arr2d
array([[1, 0, 0],
       [4, 0, 0],
       [7, 8, 9]])


布尔型索引

>>> data = np.random.randn(7, 4)
>>> data
array([[-0.31042535, -2.17572506,  0.56252532,  0.99534791],
       [ 0.63397486, -0.13189191,  0.29471484,  0.50351773],
       [ 0.51495017,  0.04994144, -0.1762269 , -0.19449053],
       [-0.07743183, -0.42964157, -1.39686796, -1.11814711],
       [-1.13909174, -0.65366514, -0.2169853 ,  0.61072596],
       [ 1.41913738, -1.2421399 ,  0.45052187, -0.17214591],
       [-0.14628746,  0.25535978, -1.04384285,  0.45418343]])
>>> names
array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'],
      dtype='|S4')
>>> names == 'Bob'
array([ True, False, False,  True, False, False, False], dtype=bool)
>>> data[names ==  'Bob']	# 布尔型数组可用于数组索引，布尔型数组的长度必须跟被索引的轴长度一致
array([[-0.31042535, -2.17572506,  0.56252532,  0.99534791],
       [-0.07743183, -0.42964157, -1.39686796, -1.11814711]])


>>> data[names ==  'Bob', 2:]	# 布尔型数组跟切片混合使用
array([[ 0.56252532,  0.99534791],
       [-1.39686796, -1.11814711]])

>>> data[names ==  'Bob', 3]
array([ 0.99534791, -1.11814711])

>>> names != 'Bob'	# 选择除“Bob”以外的其他值可以使用不等于符号(!=),也可以通过负号
array([False,  True,  True, False,  True,  True,  True], dtype=bool)
>>> data[-(names ==  'Bob')]
array([[ 0.63397486, -0.13189191,  0.29471484,  0.50351773],
       [ 0.51495017,  0.04994144, -0.1762269 , -0.19449053],
       [-1.13909174, -0.65366514, -0.2169853 ,  0.61072596],
       [ 1.41913738, -1.2421399 ,  0.45052187, -0.17214591],
       [-0.14628746,  0.25535978, -1.04384285,  0.45418343]])


>>> mask = (names == 'Bob')|(names == 'Will')
>>> mask
array([ True, False,  True,  True,  True, False, False], dtype=bool)
>>> mask1 = (names == 'Bob') & (names == 'Will')
>>> mask1
array([False, False, False, False, False, False, False], dtype=bool)
>>> data[mask]
array([[-0.31042535, -2.17572506,  0.56252532,  0.99534791],
       [ 0.51495017,  0.04994144, -0.1762269 , -0.19449053],
       [-0.07743183, -0.42964157, -1.39686796, -1.11814711],
       [-1.13909174, -0.65366514, -0.2169853 ,  0.61072596]])


>>> data
array([[-0.31042535, -2.17572506,  0.56252532,  0.99534791],
       [ 0.63397486, -0.13189191,  0.29471484,  0.50351773],
       [ 0.51495017,  0.04994144, -0.1762269 , -0.19449053],
       [-0.07743183, -0.42964157, -1.39686796, -1.11814711],
       [-1.13909174, -0.65366514, -0.2169853 ,  0.61072596],
       [ 1.41913738, -1.2421399 ,  0.45052187, -0.17214591],
       [-0.14628746,  0.25535978, -1.04384285,  0.45418343]])
>>>
>>> data[data < 0] = 0	#将data中的所有负值都设置为0
>>> data
array([[ 0.        ,  0.        ,  0.56252532,  0.99534791],
       [ 0.63397486,  0.        ,  0.29471484,  0.50351773],
       [ 0.51495017,  0.04994144,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.61072596],
       [ 1.41913738,  0.        ,  0.45052187,  0.        ],
       [ 0.        ,  0.25535978,  0.        ,  0.45418343]])

>>> data[names != 'Joe'] = 7	#
>>> data
array([[ 7.        ,  7.        ,  7.        ,  7.        ],
       [ 0.63397486,  0.        ,  0.29471484,  0.50351773],
       [ 7.        ,  7.        ,  7.        ,  7.        ],
       [ 7.        ,  7.        ,  7.        ,  7.        ],
       [ 7.        ,  7.        ,  7.        ,  7.        ],
       [ 1.41913738,  0.        ,  0.45052187,  0.        ],
       [ 0.        ,  0.25535978,  0.        ,  0.45418343]])


花式索引
>>> arr = np.empty((8,4))
>>> for i in range(8):
...     arr[i] = i
...
>>> arr
array([[ 0.,  0.,  0.,  0.],
       [ 1.,  1.,  1.,  1.],
       [ 2.,  2.,  2.,  2.],
       [ 3.,  3.,  3.,  3.],
       [ 4.,  4.,  4.,  4.],
       [ 5.,  5.,  5.,  5.],
       [ 6.,  6.,  6.,  6.],
       [ 7.,  7.,  7.,  7.]])
>>> arr[[4, 3, 0, 6]]	# 第四行，第三行，第零行 和 第六行
array([[ 4.,  4.,  4.,  4.],
       [ 3.,  3.,  3.,  3.],
       [ 0.,  0.,  0.,  0.],
       [ 6.,  6.,  6.,  6.]])

>>> arr[[-3, -5, 0, -7]]	#使用负数索引将会从末尾开始选取行
array([[ 5.,  5.,  5.,  5.],
       [ 3.,  3.,  3.,  3.],
       [ 0.,  0.,  0.,  0.],
       [ 1.,  1.,  1.,  1.]])


>>> arr = np.arange(32).reshape((8, 4)) # 一次传入多个索引数组，它返回的是一个一维数组，其中的元素对应各个索引元组
>>> arr
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15],
       [16, 17, 18, 19],
       [20, 21, 22, 23],
       [24, 25, 26, 27],
       [28, 29, 30, 31]])
>>> arr[[1, 5, 7, 2],[0, 3, 1, 2]]
array([ 4, 23, 29, 10])

>>> arr[[1, 5, 7, 2]][:,[0, 3, 1, 2]]	# 先取行，再取列
array([[ 4,  7,  5,  6],
       [20, 23, 21, 22],
       [28, 31, 29, 30],
       [ 8, 11,  9, 10]])



数组转置和轴对换
>>> arr = np.arange(15).reshape((3, 5))
>>> arr
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14]])
>>> arr.T
array([[ 0,  5, 10],
       [ 1,  6, 11],
       [ 2,  7, 12],
       [ 3,  8, 13],
       [ 4,  9, 14]])



>>> arr = np.arange(16).reshape((2, 2, 4))
>>> arr
array([[[ 0,  1,  2,  3],
        [ 4,  5,  6,  7]],

       [[ 8,  9, 10, 11],
        [12, 13, 14, 15]]])
>>> arr.transpose((1, 0, 2))
array([[[ 0,  1,  2,  3],
        [ 8,  9, 10, 11]],

       [[ 4,  5,  6,  7],
        [12, 13, 14, 15]]])
>>> arr.transpose((1, 2, 0))
array([[[ 0,  8],
        [ 1,  9],
        [ 2, 10],
        [ 3, 11]],

       [[ 4, 12],
        [ 5, 13],
        [ 6, 14],
        [ 7, 15]]])

我说你来试一下哈：
arr1.shape 应该是(2, 2, 4) 意为 2维，2*4矩阵

arr1.transpose(*args) 里面的参数，可以这么理解，他是调换arr1.shape的顺序，咱来给arr1.shape标一下角标哈，（2[0], 2[1], 4[2]）  [ ] 里是shape的索引，对吧， 
transpose((1, 0, 2)) 的意思是 按照这个顺序 重新设置shape 也就是 （2[1], 2[0], 4[2]）

 虽然看起来 变换前后的shape都是 2,2,4  ， 但是问题来了，transpose是转置
shape按照(1,0,2)的顺序重新设置了， array里的所有元素 也要按照这个规则重新组成新矩阵

 比如 8 在arr1中的索引是 (1, 0, 0)  那么按照刚才的变换规则，就是 (0, 1, 0) 看看跟你结果arr2的位置一样了吧，依此类推...



通用函数:快速的元素级数组函数
>>> import numpy as np
>>> arr = np.arange(10)
>>> np.sqrt(arr)
array([ 0.        ,  1.        ,  1.41421356,  1.73205081,  2.        ,
        2.23606798,  2.44948974,  2.64575131,  2.82842712,  3.        ])
>>> np.exp(arr)
array([  1.00000000e+00,   2.71828183e+00,   7.38905610e+00,
         2.00855369e+01,   5.45981500e+01,   1.48413159e+02,
         4.03428793e+02,   1.09663316e+03,   2.98095799e+03,
         8.10308393e+03])
sqrt和exp是一元（unary）ufunc，另外一些（如add或maximum）接受2个数组，也叫二元数组

>>> x = np.random.randn(8)
>>> y = np.random.randn(8)
>>> x
array([-1.09442604, -1.43680231, -0.28154207,  0.84074478, -0.18878751,
        0.50501874,  0.28835676,  1.85865484])
>>> y
array([ 0.97924522, -0.94704341,  0.04190887,  1.60123804,  0.12770678,
        0.04152567, -0.11783759, -0.75930132])
>>> np.maximum(x, y)
array([ 0.97924522, -0.94704341,  0.04190887,  1.60123804,  0.12770678,
        0.50501874,  0.28835676,  1.85865484])

>>> arr = np.random.randn(7)*5
>>> arr
array([ -9.17367478,   0.71396009, -10.1828497 ,   0.45724798,
        -1.05427677,   3.08732191,  -0.73990597])
>>> np.modf(arr)	# 返回两个数组 一个是小数部分，一个是整数部分
(array([-0.17367478,  0.71396009, -0.1828497 ,  0.45724798, -0.05427677,
        0.08732191, -0.73990597]), array([ -9.,   0., -10.,   0.,  -1.,   3.,  -0.]))



利用数组进行数据处理
>>> points = np.arange(-5, 5, 0.01)
>>> xs, ys = np.meshgrid(points, points)	#生成网格，两个二维数组
>>> ys
array([[-5.  , -5.  , -5.  , ..., -5.  , -5.  , -5.  ],
       [-4.99, -4.99, -4.99, ..., -4.99, -4.99, -4.99],
       [-4.98, -4.98, -4.98, ..., -4.98, -4.98, -4.98],
       ...,
       [ 4.97,  4.97,  4.97, ...,  4.97,  4.97,  4.97],
       [ 4.98,  4.98,  4.98, ...,  4.98,  4.98,  4.98],
       [ 4.99,  4.99,  4.99, ...,  4.99,  4.99,  4.99]])
>>> xs
array([[-5.  , -4.99, -4.98, ...,  4.97,  4.98,  4.99],
       [-5.  , -4.99, -4.98, ...,  4.97,  4.98,  4.99],
       [-5.  , -4.99, -4.98, ...,  4.97,  4.98,  4.99],
       ...,
       [-5.  , -4.99, -4.98, ...,  4.97,  4.98,  4.99],
       [-5.  , -4.99, -4.98, ...,  4.97,  4.98,  4.99],
       [-5.  , -4.99, -4.98, ...,  4.97,  4.98,  4.99]])
>>> import matplotlib.pyplot as plt
>>> z = np.sqrt(xs**2 + ys**2)
>>> z
array([[ 7.07106781,  7.06400028,  7.05693985, ...,  7.04988652,
         7.05693985,  7.06400028],
       [ 7.06400028,  7.05692568,  7.04985815, ...,  7.04279774,
         7.04985815,  7.05692568],
       [ 7.05693985,  7.04985815,  7.04278354, ...,  7.03571603,
         7.04278354,  7.04985815],
       ...,
       [ 7.04988652,  7.04279774,  7.03571603, ...,  7.0286414 ,
         7.03571603,  7.04279774],
       [ 7.05693985,  7.04985815,  7.04278354, ...,  7.03571603,
         7.04278354,  7.04985815],
       [ 7.06400028,  7.05692568,  7.04985815, ...,  7.04279774,
         7.04985815,  7.05692568]])
>>> plt.imshow(z, cmap=plt.cm.gray);plt.colorbar()
<matplotlib.image.AxesImage object at 0x062666B0>
<matplotlib.colorbar.Colorbar object at 0x062BE0D0>
>>> plt.show()


将条件逻辑表述为数组运算
假设我们要根据cond中的值选取xarr和yarr的值：当cond中的值为True时，选取xarr的值
否则从yarr中选取
>>> import numpy as np
>>> xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])
>>> yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])
>>> cond = np.array([True, False, True, True, False])
>>> result = np.where(cond, xarr, yarr)
>>> result
array([ 1.1,  2.2,  1.3,  1.4,  2.5])

np.where的第二个和第三个参数不必是数组，它们都是可以是标量值。在数据分析工作中
，where通常用于根据另一个数组而产生一个新的数组。


>>> arr = np.random.randn(4,4)
>>> arr
array([[-0.32285005,  0.25847681,  0.66953569,  1.7002404 ],
       [ 0.22827269,  1.02391622, -0.8919314 ,  0.38018606],
       [ 0.3845627 ,  0.84781941, -0.28423424,  1.73434853],
       [-0.76948816,  0.36355368,  1.56517939,  0.00546952]])
>>> np.where(arr > 0, 2, -2)	# 将数组中大于零的换成2，小于零的换成-2
array([[-2,  2,  2,  2],
       [ 2,  2, -2,  2],
       [ 2,  2, -2,  2],
       [-2,  2,  2,  2]])
>>> np.where(arr > 0, 2, arr)	# 只将数组中大于零的换成2
array([[-0.32285005,  2.        ,  2.        ,  2.        ],
       [ 2.        ,  2.        , -0.8919314 ,  2.        ],
       [ 2.        ,  2.        , -0.28423424,  2.        ],
       [-0.76948816,  2.        ,  2.        ,  2.        ]])



数学和统计方法
>>> arr = np.random.randn(5,4)
>>> arr
array([[-1.71504642,  0.22678685,  0.74513757,  1.70279446],
       [-0.34902157,  0.27176852, -1.52373216, -0.24647356],
       [-0.49901881, -0.11396496, -0.00902927, -0.30132351],
       [-0.44314036, -0.10644648, -1.3300278 , -3.00895452],
       [-0.26927576, -0.61164494, -1.39029488, -0.08084923]])
>>> arr.mean()		# 数组的平均数
-0.45258784121946649
>>> np.mean(arr)	# 数组的平均数
-0.45258784121946649
>>> arr.sum()
-9.0517568243893294	# 数组的和
>>> arr
array([[-1.71504642,  0.22678685,  0.74513757,  1.70279446],
       [-0.34902157,  0.27176852, -1.52373216, -0.24647356],
       [-0.49901881, -0.11396496, -0.00902927, -0.30132351],
       [-0.44314036, -0.10644648, -1.3300278 , -3.00895452],
       [-0.26927576, -0.61164494, -1.39029488, -0.08084923]])
>>> arr.mean(axis = 1)		# 每一行的平均数
array([ 0.23991811, -0.46186469, -0.23083414, -1.22214229, -0.5880162 ])
>>> arr.mean(axis = 0)		# 每一列的平均数
array([-0.65510058, -0.0667002 , -0.70158931, -0.38696127])


>>> arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
>>> arr.cumsum(0)	# 沿列的方向 每一行加下一行
array([[ 0,  1,  2],
       [ 3,  5,  7],
       [ 9, 12, 15]])
>>> arr.cumsum(1)	# 沿行的方向 每一列加下一列
array([[ 0,  1,  3],
       [ 3,  7, 12],
       [ 6, 13, 21]])
>>> arr.cumprod(1)
array([[  0,   0,   0],
       [  3,  12,  60],
       [  6,  42, 336]])
>>> arr.cumprod(0)
array([[ 0,  1,  2],
       [ 0,  4, 10],
       [ 0, 28, 80]])


用于布尔型数组的方法
>>> import numpy as np
>>> arr = np.random.randn(100)
>>> (arr > 0).sum()	# sum经常被用来对布尔型数组
58

>>> bools = np.array([False, False, True, False])
>>> bools.any()	# 用于测试有一个或多个True
True
>>> bools.all()	# 用于测试数组中是否全是True
False
这两个方法也能用于非布尔型数组，所有非0元素会被当做True


排序
>>> arr = np.random.randn(8)
>>> arr
array([-1.50790127, -1.22640436, -0.00729792, -0.42537421, -0.93833854,
       -0.6814844 ,  1.32235945, -0.09862056])
>>> arr.sort()
>>> arr
array([-1.50790127, -1.22640436, -0.93833854, -0.6814844 , -0.42537421,
       -0.09862056, -0.00729792,  1.32235945])


>>> arr = np.random.randn(3,3)
>>> arr
array([[-1.61589688, -0.65173118,  0.14666864],
       [ 0.87499686,  0.50801178, -0.06954368],
       [ 1.0262651 ,  1.08821325, -0.45640651]])
>>> arr.sort(1)		# 水平轴向sort
>>> arr
array([[-1.61589688, -0.65173118,  0.14666864],
       [-0.06954368,  0.50801178,  0.87499686],
       [-0.45640651,  1.0262651 ,  1.08821325]])


>>> arr = np.random.randn(3,3)
>>> arr
array([[ 1.42633942, -0.48664113,  0.02979959],
       [ 0.62360729,  0.57903973,  1.68476841],
       [ 0.94767599, -0.15832117,  0.97161712]])
>>> np.sort(arr)	# np.sort是已排序数组的副本
array([[-0.48664113,  0.02979959,  1.42633942],
       [ 0.57903973,  0.62360729,  1.68476841],
       [-0.15832117,  0.94767599,  0.97161712]])
>>> arr
array([[ 1.42633942, -0.48664113,  0.02979959],
       [ 0.62360729,  0.57903973,  1.68476841],
       [ 0.94767599, -0.15832117,  0.97161712]])

>>> large_arr = np.random.randn(1000)	# 计算数组分位数最简单的办法是对其进行排序，然后选取特定位置的值
>>> large_arr.sort()
>>> large_arr[int(0.05*len(large_arr))]
-1.5109867022543568


唯一化以及其他的集合逻辑
>>> import numpy as np
>>> names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])
>>> names
array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'],
      dtype='|S4')
>>> np.unique(names)	# 找出数组中的唯一值并返回已排序的结果
array(['Bob', 'Joe', 'Will'],
      dtype='|S4')

>>> ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])
>>> np.unique(ints)
array([1, 2, 3, 4])


>>> values = np.array([6, 0, 0, 3, 2, 5, 6])	# 另一个函数np.in1d用于测试一个数组中的
>>> np.in1d(values, [2, 3, 6])			# 值在另一个数组中的成员资格，返回一个布尔型数组
array([ True, False, False,  True,  True, False,  True], dtype=bool)


线性代数

>>> import numpy as np
>>> x = np.array([[1, 2, 3], [4, 5, 6]])
>>> y = np.array([[6, 23], [-1, 7], [8, 9]])
>>> x
array([[1, 2, 3],
       [4, 5, 6]])
>>> y
array([[ 6, 23],
       [-1,  7],
       [ 8,  9]])
>>> np.dot(x, y)
array([[ 28,  64],
       [ 67, 181]])


>>> z = np.ones(3)
>>> z
array([ 1.,  1.,  1.])
>>> x
array([[1, 2, 3],
       [4, 5, 6]])
>>> np.dot(x, z)
array([  6.,  15.])


>>> from numpy.linalg import inv, qr
>>> X = np.array([[2,3],[4,5]])
>>> X
array([[2, 3],
       [4, 5]])
>>> M = X.T	# 求X的转置矩阵
>>> M
array([[2, 4],	
       [3, 5]])
>>> X.T.dot(X)	# 先求X的转置矩阵然后与X点乘，XT*X
array([[20, 26],
       [26, 34]])

>>> X
array([[2, 3],
       [4, 5]])
>>> inv(X)	# inv求X的逆矩阵
array([[-2.5,  1.5],
       [ 2. , -1. ]])
>>> inv(X).dot(X)	# 互逆矩阵乘积为I
array([[ 1.,  0.],
       [ 0.,  1.]])


随机数生成
>>> nsteps = 1000
>>> draws = np.random.randint(0, 2, size=nsteps)	# 随机生成100
>>> steps = np.where(draws > 0, 1, -1)
>>> walk = steps.cumsum()
>>> walk.min()
-24
>>> walk.max()
19




###################################
############pandas入门#############
###################################


>>> from pandas import Series, DataFrame
>>> import pandas as pd
>>> obj = Series([4, 7, -5, 3])
>>> obj
0    4
1    7
2   -5
3    3
dtype: int64

>>> obj.values
array([ 4,  7, -5,  3])
>>> obj.index
RangeIndex(start=0, stop=4, step=1)
>>>
>>> obj2 = Series([4, 7, -5, 3], index = ['d', 'b', 'a', 'c'])
>>> obj2
d    4
b    7
a   -5
c    3
dtype: int64
>>> obj2['a']
-5
>>> obj2.index
Index([u'd', u'b', u'a', u'c'], dtype='object')

与普通NumPy数组相比，你可以通过索引的方式选取Series中的单个或一组值：
>>> from pandas import Series, DataFrame
>>> import pandas as pd
>>> obj2 = Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])
>>> obj2['a']
-5
>>> obj2['d'] = 10
>>> obj2
d    10
b     7
a    -5
c     3
dtype: int64
>>> obj2[['c', 'a', 'd']]
c     3
a    -5
d    10
dtype: int64


NumPy数组运算（如根据布尔型数组进行过滤、标量乘法、应用数学函数等）都会保留索引和
值之间的链接
>>> obj2
d    10
b     7
a    -5
c     3
dtype: int64
>>> obj2[obj2 > 0]
d    10
b     7
c     3
dtype: int64

>>> obj2*2
d    20
b    14
a   -10
c     6

>>> import numpy as np
>>> np.exp(obj2)
d    22026.465795
b     1096.633158
a        0.006738
c       20.085537


将Series看成是一个定长的有序字典，因为它是索引值到数据值的一个映射。
它可以用在许多原本需要字典参数的函数中
>>> 'b' in obj2
True
>>> 'e' in obj2
False

如果数据被放在一个Python字典中，也可以直接通过这个字典来创建Series：
>>> sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon' : 16000,
>>> obj3 = Series(sdata)
>>> obj3
Ohio      35000
Oregon    16000
Texas     71000
Utah       5000
dtype: int64

sdata中跟states索引相匹配的那3个值会被找出来并放到相应
的位置上，但由于"California"所对应的sdata值找不到，所以其结果为NaN
>>> states = ['California', 'Ohio', 'Oregon', 'Texas']
>>> obj4 = Series(sdata, index = states)
>>> obj4
California        NaN
Ohio          35000.0
Oregon        16000.0
Texas         71000.0
dtype: float64


pandas的isnull和notnull函数可用于检测缺失数据：
>>> pd.isnull(obj4)
California     True
Ohio          False
Oregon        False
Texas         False
dtype: bool
>>> pd.notnull(obj4)
California    False
Ohio           True
Oregon         True
Texas          True
dtype: bool


Series最重要的一个功能是：它在算术运算中会自动
对齐不同索引的数据
>>> obj3
Ohio      35000
Oregon    16000
Texas     71000
Utah       5000
dtype: int64
>>> obj4
California        NaN
Ohio          35000.0
Oregon        16000.0
Texas         71000.0
dtype: float64
>>> obj3 + obj4
California         NaN
Ohio           70000.0
Oregon         32000.0
Texas         142000.0
Utah               NaN
dtype: float64


Series对象本身及其索引都有一个name属性，该属性跟pandas其他的
功能非常密切：
>>> obj4.name = 'population'
>>> obj4.index.name = 'state'
>>> obj4
state
California        NaN
Ohio          35000.0
Oregon        16000.0
Texas         71000.0
Name: population, dtype: float64


Series的索引可以通过赋值的方式就地修改：
>>> obj = Series([4, 7, -5, 3])
>>> obj
0    4
1    7
2   -5
3    3
dtype: int64
>>> obj
0    4
1    7
2   -5
3    3
dtype: int64
>>> obj.index=['Bob', 'Steve', 'Jeff', 'Ryan']
>>> obj
Bob      4
Steve    7
Jeff    -5
Ryan     3
dtype: int64


DataFrame表格型数据结构
>>> data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],
... 'year': [2000, 2001, 2002, 2001, 2002],
... 'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}
>>> frame = DataFrame(data)
>>> frame
   pop   state  year
0  1.5    Ohio  2000
1  1.7    Ohio  2001
2  3.6    Ohio  2002
3  2.4  Nevada  2001
4  2.9  Nevada  2002


如果指定了列序列，则DataFrame的列就会按照指定顺序进行排序
>>> DataFrame(data, columns = ['year', 'state', 'pop'])
   year   state  pop
0  2000    Ohio  1.5
1  2001    Ohio  1.7
2  2002    Ohio  3.6
3  2001  Nevada  2.4
4  2002  Nevada  2.9

跟Series一样，如果传入的列在数据中找不到，就会产生NA值：
>>> frame2 = DataFrame(data, columns=['year', 'state', 'pop', 'debt'],
... index = ['one', 'two', 'three', 'four', 'five'])
>>> frame2
       year   state  pop debt
one    2000    Ohio  1.5  NaN
two    2001    Ohio  1.7  NaN
three  2002    Ohio  3.6  NaN
four   2001  Nevada  2.4  NaN
five   2002  Nevada  2.9  NaN



通过类似字典标记的方式或属性的方式，可以将DataFrame的列获取为一个Series：
>>> frame2['state']
one        Ohio
two        Ohio
three      Ohio
four     Nevada
five     Nevada
Name: state, dtype: object
>>> frame['year']
0    2000
1    2001
2    2002
3    2001
4    2002
Name: year, dtype: int64

行也可以通过位置或名称的方式进行获取，比如用索引字段ix
>>> frame2.ix['three']
year     2002
state    Ohio
pop       3.6
debt      NaN

>>> frame2
       year   state  pop debt
one       1    Ohio  1.5  NaN
two    2001    Ohio  1.7  NaN
three  2002    Ohio  3.6  NaN
four   2001  Nevada  2.4  NaN
five   2002  Nevada  2.9  NaN
>>> frame2['debt']['one']=2
>>> frame2
       year   state  pop debt
one       1    Ohio  1.5    2
two    2001    Ohio  1.7  NaN
three  2002    Ohio  3.6  NaN
four   2001  Nevada  2.4  NaN
five   2002  Nevada  2.9  NaN


列可以通过赋值的方式进行修改。
>>> frame2['debt'] = np.arange(5.)
>>> frame2
       year   state  pop  debt
one    2000    Ohio  1.5   0.0
two    2001    Ohio  1.7   1.0
three  2002    Ohio  3.6   2.0
four   2001  Nevada  2.4   3.0
five   2002  Nevada  2.9   4.0


将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。
>>> val = Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])
>>> frame2['debt'] = val
>>> frame2
       year   state  pop  debt
one    2000    Ohio  1.5   NaN
two    2001    Ohio  1.7  -1.2
three  2002    Ohio  3.6   NaN
four   2001  Nevada  2.4  -1.5
five   2002  Nevada  2.9  -1.7


为不存在的列赋值会创建出一个新列。关键字del用于删除列：
>>> frame2['eastern'] = frame2.state == 'Ohio'
>>> frame2
       year   state  pop  debt eastern
one    2000    Ohio  1.5   NaN    True
two    2001    Ohio  1.7  -1.2    True
three  2002    Ohio  3.6   NaN    True
four   2001  Nevada  2.4  -1.5   False
five   2002  Nevada  2.9  -1.7   False


另一种常见的数据形式是嵌套字典（也就是字典的字典）
>>> pop = {'Nevada': {2001: 2.4, 2002: 2.9},
... 'Ohio':{2000: 1.5, 2001: 1.7, 2002: 3.6}}
>>> frame3 = DataFrame(pop)
>>> frame3
      Nevada  Ohio
2000     NaN   1.5
2001     2.4   1.7
2002     2.9   3.6

转置
>>> frame3.T
        2000  2001  2002
Nevada   NaN   2.4   2.9
Ohio     1.5   1.7   3.6

由Series组成的字典差不多也是一样的用法：
>>> pdata = {'Ohio':frame3['Ohio'][:-1],
... 'Nevada': frame3['Nevada'][:2]}
>>> DataFrame(pdata)
      Nevada  Ohio
2000     NaN   1.5
2001     2.4   1.7


如果设置了DataFrame的index和columns的name属性，则这些信息也会被显示出来
>>> frame3.index.name = 'year'
>>> frame3.columns.name = 'state'
>>> frame3
state  Nevada  Ohio
year
2000      NaN   1.5
2001      2.4   1.7
2002      2.9   3.6


跟Series一样，values属性也会以二维ndarray的形式返回DataFrame中的数据：
>>> frame3.values
array([[ nan,  1.5],
       [ 2.4,  1.7],
       [ 2.9,  3.6]])
>>> frame2.values
array([[2000, 'Ohio', 1.5, nan, True],
       [2001, 'Ohio', 1.7, -1.2, True],
       [2002, 'Ohio', 3.6, nan, True],
       [2001, 'Nevada', 2.4, -1.5, False],
       [2002, 'Nevada', 2.9, -1.7, False]], dtype=object)



二维ndarry可以输入给DataFrame构造器的数据
>>> xarr = np.array([[1, 2, 3], [2, 4, 6]])
>>> xarr
array([[1, 2, 3],
       [2, 4, 6]])
>>> frame5 = DataFrame(xarr)
>>> frame5
   0  1  2
0  1  2  3
1  2  4  6
>>> frame5 = DataFrame(xarr, columns=['A', 'B','F'], index = ['C', 'D'])
>>> frame5
   A  B  F
C  1  2  3
D  2  4  6

索引对象
>>> obj = Series(range(3), index=['a', 'b', 'c'])
>>> obj
a    0
b    1
c    2
dtype: int64
>>> index = obj.index
>>> index
Index([u'a', u'b', u'c'], dtype='object')
>>> index[1:]
Index([u'b', u'c'], dtype='object')

Index对象是不可修改的
>>> index[1]
'b'
>>> index[1] = 'd'
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/opt/linux/centos/7.x/x86_64/pkgs/python/2.7.5/lib64/python2.7/site-packages/pandas/indexes/base.py", line 1237, in __setitem__
    raise TypeError("Index does not support mutable operations")
TypeError: Index does not support mutable operations

不可修改性非常重要，因为这样才能使Index对象在多个数据结构之间安全共享
>>> obj2 = Series([1.5, -2.5, 0], index=index)
>>> obj2
0    1.5
1   -2.5
2    0.0
dtype: float64
>>> obj2.index is index
True


Index的功能也类似一个固定大小的集合
>>> import pandas as pd
>>> from pandas import Series, DataFrame
>>>
>>>
>>> pop = {'Nevada':{2001: 2.4, 2002: 2.9},
... 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}
>>> frame3 = DataFrame(pop)
>>> frame3
      Nevada  Ohio
2000     NaN   1.5
2001     2.4   1.7
2002     2.9   3.6

>>> pdata={'Ohio':frame3['Ohio'][:-1],	# 到最后个为止
... 'Nevada':frame3['Nevada'][:2]}	# 输出第0个，第1个
>>> DataFrame(pdata)
      Nevada  Ohio
2000     NaN   1.5
2001     2.4   1.7

>>> 'Ohio' in frame3.columns
True
>>> 2003 in frame3.index
False


索引对象






基本功能
重新索引 reindex
>>> obj = Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])
>>> obj
d    4.5
b    7.2
a   -5.3
c    3.6
dtype: float64
>>> obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e']) # 调用该Series的reindex将会根据新索引
>>> obj
d    4.5
b    7.2
a   -5.3
c    3.6
dtype: float64
>>> obj2
a   -5.3
b    7.2
c    3.6
d    4.5
e    NaN
dtype: float64

>>> obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'], fill_value=0)# 用fill_value来填充值
>>> obj2
a   -5.3
b    7.2
c    3.6
d    4.5
e    0.0
dtype: float64


对于时间序列这样的有序数据，需要插值处理
>>> obj3 = Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])	
>>> obj3.reindex(range(6), method = 'ffill')	# method选项 可进行插值处理 ffill 前向插值，和前面的一样
0      blue
1      blue
2    purple
3    purple
4    yellow
5    yellow
dtype: object

>>> obj3.reindex(range(5), method = 'bfill')	# bfill 后向引用 和后面的一样
0      blue
1    purple
2    purple
3    yellow
4    yellow


对于DataFrame，reindex可以修改（行）索引、列，或两个都修改。如果仅转入一个序列，则会重新
索引行：
>>> frame = DataFrame(np.arange(9).reshape((3, 3)), index = ['a', 'c', 'd'], columns = ['Ohio', 'Texas', 'California'])
>>> frame
   Ohio  Texas  California
a     0      1           2
c     3      4           5
d     6      7           8


>>> import numpy as np
>>> frame = DataFrame(np.arange(9).reshape((3, 3)), index = ['a', '               umns = ['Ohio', 'Texas', 'California'])
>>> frame
   Ohio  Texas  California
a     0      1           2
c     3      4           5
d     6      7           8
>>> frame2 = frame.reindex(['a', 'b', 'c', 'd'])
>>> frame2
   Ohio  Texas  California
a   0.0    1.0         2.0
b   NaN    NaN         NaN
c   3.0    4.0         5.0
d   6.0    7.0         8.0
>>> states = ['Texas', 'Utah', 'California']
>>> frame.reindex(columns = states)
   Texas  Utah  California
a      1   NaN           2
c      4   NaN           5
d      7   NaN           8

也可以同时对行和列进行重新索引，而插值则只能按行引用（即轴0）：
>>> frame.reindex(index=['a', 'b', 'c', 'd'], method='ffill', columns=states)
   Texas  Utah  California
a      1   NaN           2
b      1   NaN           2
c      4   NaN           5
d      7   NaN           8


利用ix的标签索引功能，重新索引任务可以变得更简洁：
>>> frame.ix[['a', 'b', 'c', 'd'], states]
   Texas  Utah  California
a    1.0   NaN         2.0
b    NaN   NaN         NaN
c    4.0   NaN         5.0
d    7.0   NaN         8.0


丢弃指定轴上的项
>>> obj = Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])
>>> obj
a    0.0
b    1.0
c    2.0
d    3.0
e    4.0
dtype: float64
>>> new_obj = obj.drop('c')	# drop方法返回的是一个在指定轴上删除了指定值的新对象
>>> new_obj
a    0.0
b    1.0
d    3.0
e    4.0
dtype: float64
>>> obj.drop(['d', 'c'])
a    0.0
b    1.0
e    4.0
dtype: float64


对于DataFrame，可以删除任意轴上的索引值：
>>> data = DataFrame(np.arange(16).reshape((4, 4)),
... index=['Ohio', 'Colorado', 'Utah', 'New York'],
... columns=['one', 'two', 'three', 'four'])
>>>
>>> data
          one  two  three  four
Ohio        0    1      2     3
Colorado    4    5      6     7
Utah        8    9     10    11
New York   12   13     14    15

>>> data.drop(['Colorado', 'Ohio'])
          one  two  three  four
Utah        8    9     10    11
New York   12   13     14    15

>>> data.drop('two', axis=1)
          one  three  four
Ohio        0      2     3
Colorado    4      6     7
Utah        8     10    11
New York   12     14    15

>>> data.drop(['two', 'four'], axis=1)	
          one  three
Ohio        0      2
Colorado    4      6
Utah        8     10
New York   12     14


索引、选取和过滤
>>> obj=Series(np.arange(4.), index=['a', 'b', 'c', 'd'])
>>> obj
a    0.0
b    1.0
c    2.0
d    3.0
dtype: float64
>>> obj['b']
1.0
>>> obj[1]
1.0
>>> obj[2:4]
c    2.0
d    3.0
dtype: float64
>>> obj[['b','a','d']]
b    1.0
a    0.0
d    3.0
dtype: float64
>>> obj[[1,3]]
b    1.0
d    3.0
dtype: float64
>>> obj[obj<2]
a    0.0
b    1.0
dtype: float64

利用标签的切片运算与普通的python切片不同，其末端是包含的
>>> obj['b':'c']=5
>>> obj
a    0.0
b    5.0
c    5.0
d    3.0
dtype: float64


>>> data=DataFrame(np.arange(16).reshape((4,4)),
... index=['Ohio', 'Colorado', 'Utah', 'New York'],
... columns=['one','two','three','four'])
>>> data
          one  two  three  four
Ohio        0    1      2     3
Colorado    4    5      6     7
Utah        8    9     10    11
New York   12   13     14    15
>>> data['two']
Ohio         1
Colorado     5
Utah         9
New York    13
Name: two, dtype: int32
>>> data[['three','one']]
          three  one
Ohio          2    0
Colorado      6    4
Utah         10    8
New York     14   12


>>> data=DataFrame(np.arange(16).reshape((4,4)),
... index=['Ohio', 'Colorado', 'Utah', 'New York'],
... columns=['one','two','three','four'])
>>> data
          one  two  three  four
Ohio        0    1      2     3
Colorado    4    5      6     7
Utah        8    9     10    11
New York   12   13     14    15
>>> data['two']	# 选取DataFrame中的列
Ohio         1
Colorado     5
Utah         9
New York    13
Name: two, dtype: int32
>>> data[['three','one']]	# 选取DataFrame中的两列
          three  one
Ohio          2    0
Colorado      6    4
Utah         10    8
New York     14   12
>>> data[:2]			# 选取data中的两行
          one  two  three  four
Ohio        0    1      2     3
Colorado    4    5      6     7
>>> data[data['three']>5]	# 布尔运算
          one  two  three  four
Colorado    4    5      6     7
Utah        8    9     10    11
New York   12   13     14    15


这段代码的目的是使DataFrame在语法上更像ndarray
>>> data<5
            one    two  three   four
Ohio       True   True   True   True
Colorado   True  False  False  False
Utah      False  False  False  False
New York  False  False  False  False
>>>
>>>
>>>
>>> data[data<5]=0
>>> data
          one  two  three  four
Ohio        0    0      0     0
Colorado    0    5      6     7
Utah        8    9     10    11
New York   12   13     14    15


为了在DataFrame的行上进行标签索引，引入专门的索引字段ix

>>> data
          one  two  three  four
Ohio        0    0      0     0
Colorado    0    5      6     7
Utah        8    9     10    11
New York   12   13     14    15
>>> data.ix['Colorado', ['two', 'three']]	# Colorado行， two列和three列
two      5
three    6
Name: Colorado, dtype: int32
>>> data.ix[['Colorado','Utah'],[3, 0, 1]]	# Colorado，Utah行以及3,0,1列
          four  one  two
Colorado     7    0    5
Utah        11    8    9


>>> data
          one  two  three  four
Ohio        0    0      0     0
Colorado    0    5      6     7
Utah        8    9     10    11
New York   12   13     14    15
>>> data.ix[2]					# 选取第三行
one       8
two       9
three    10
four     11
Name: Utah, dtype: int32


>>> data.ix[:'Utah', 'two']			# 从第一行到Utah行的第二列
Ohio        0
Colorado    5
Utah        9


>>> data.ix[data.three > 5, :3]			# three列大于5的行，第一列到第三列
          one  two  three
Colorado    0    5      6
Utah        8    9     10
New York   12   13     14
>>> data
          one  two  three  four
Ohio        0    0      0     0
Colorado    0    5      6     7
Utah        8    9     10    11
New York   12   13     14    15
>>> data.ix[data.three > 5, :1]
          one
Colorado    0
Utah        8
New York   12
>>> data.ix[data.three > 5, :0]
Empty DataFrame
Columns: []
Index: [Colorado, Utah, New York]


算术运算和数据对齐
>>> s1=Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])
>>> s2=Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f' ,'g'])
>>> s1+s2	# 如果直接相加，非重叠部分会显示NaN
a    5.2
c    1.1
d    NaN
e    0.0
f    NaN
g    NaN
dtype: float64
>>> s1.add(s2, fill_value=0)	# add方法以及fill_value参数
a    5.2
c    1.1
d    3.4
e    0.0
f    4.0
g    3.1
dtype: float64


DataFrame和Series之间的运算
>>> arr=np.arange(12.).reshape((3,4))
>>> arr
array([[  0.,   1.,   2.,   3.],
       [  4.,   5.,   6.,   7.],
       [  8.,   9.,  10.,  11.]])
>>> arr[0]
array([ 0.,  1.,  2.,  3.])
>>> arr-arr[0]
array([[ 0.,  0.,  0.,  0.],
       [ 4.,  4.,  4.,  4.],
       [ 8.,  8.,  8.,  8.]])


>>> frame=DataFrame(np.arange(12.).reshape((4,3)),columns=list('bde'),
... index=['Utah', 'Ohio', 'Texas', 'Oregon'])
>>> series=frame.ix[0]
>>> frame
          b     d     e
Utah    0.0   1.0   2.0
Ohio    3.0   4.0   5.0
Texas   6.0   7.0   8.0
Oregon  9.0  10.0  11.0
>>> series
b    0.0
d    1.0
e    2.0
Name: Utah, dtype: float64
>>> frame-series
          b    d    e
Utah    0.0  0.0  0.0
Ohio    3.0  3.0  3.0
Texas   6.0  6.0  6.0
Oregon  9.0  9.0  9.0
>>> series2=Series(range(3), index=['b', 'e', 'f'])
>>> frame+series2
          b   d     e   f
Utah    0.0 NaN   3.0 NaN
Ohio    3.0 NaN   6.0 NaN
Texas   6.0 NaN   9.0 NaN
Oregon  9.0 NaN  12.0 NaN
>>> series3=frame['d']
>>> frame
          b     d     e
Utah    0.0   1.0   2.0
Ohio    3.0   4.0   5.0
Texas   6.0   7.0   8.0
Oregon  9.0  10.0  11.0
>>> series3
Utah       1.0
Ohio       4.0
Texas      7.0
Oregon    10.0
Name: d, dtype: float64
>>> frame.sub(series3)
        Ohio  Oregon  Texas  Utah   b   d   e
Utah     NaN     NaN    NaN   NaN NaN NaN NaN
Ohio     NaN     NaN    NaN   NaN NaN NaN NaN
Texas    NaN     NaN    NaN   NaN NaN NaN NaN
Oregon   NaN     NaN    NaN   NaN NaN NaN NaN
>>> frame.sub(series3, axis=0)	# 匹配行 且在列广播
          b    d    e
Utah   -1.0  0.0  1.0
Ohio   -1.0  0.0  1.0
Texas  -1.0  0.0  1.0
Oregon -1.0  0.0  1.0



###函数应用和映射###

对DataFrame中各个元素，或一行/列数据进行函数操作
>>> frame=DataFrame(np.random.randn(4,3), columns=list('bde'),
... index=['Utah', 'Ohio', 'Texas', 'Oregon'])
>>> frame
               b         d         e
Utah   -1.766152 -2.626653 -0.445074
Ohio   -0.292650  0.801737 -0.572183
Texas  -2.034327 -1.394547 -0.839812
Oregon  0.067651  0.847935 -0.979156
>>> np.abs(frame)	# NumPy的ufuns（元素级数组方法）也可用于操作pandas对象
               b         d         e
Utah    1.766152  2.626653  0.445074
Ohio    0.292650  0.801737  0.572183
Texas   2.034327  1.394547  0.839812
Oregon  0.067651  0.847935  0.979156


>>> f = lambda x: x.max()-x.min()	# DataFrame的apply方法即可实现将函数应用到由
>>> frame.apply(f)			# apply（）各列和行所形成的一维数组上
b    2.101978
d    3.474588
e    0.534083
dtype: float64
>>> frame.apply(f, axis=1)
Utah      2.181580
Ohio      1.373920
Texas     1.194515
Oregon    1.827091
dtype: float64


>>> def f(x):
...     return Series([x.min(), x.max()], index=['min', 'max'])
...
>>> frame.apply(f)			# 传递给apply的函数返回由多个值组成的Series
            b         d         e
min -2.034327 -2.626653 -0.979156
max  0.067651  0.847935 -0.445074


>>> format = lambda x: '%.2f' % x	# 得到frame中各个浮点值的格式化字符串用applymap
>>> frame.applymap(format)
            b      d      e
Utah    -1.77  -2.63  -0.45
Ohio    -0.29   0.80  -0.57
Texas   -2.03  -1.39  -0.84
Oregon   0.07   0.85  -0.98


>>> frame['e'].map(format)	# Series有一个用于应用元素级函数的map方法

Utah      -0.45
Ohio      -0.57
Texas     -0.84
Oregon    -0.98
Name: e, dtype: object


###排序和排名###
>>> obj = Series(range(4), index=['d', 'a', 'b', 'c'])
>>> obj
d    0
a    1
b    2
c    3
dtype: int64

>>> obj.sort_index()
a    1
b    2
c    3
d    0
dtype: int64

>>> frame=DataFrame(np.arange(8).reshape((2,4)), index=['three', 'one'],	# 对于DataFrame，则可以根据任意一个轴上的索引进行排序
... columns=['d', 'a', 'b', 'c'])
>>>
>>>
>>> frame
       d  a  b  c
three  0  1  2  3
one    4  5  6  7
>>> frame.sort_index()
       d  a  b  c
one    4  5  6  7
three  0  1  2  3
>>> frame.sort_index(axis=1)
       a  b  c  d
three  1  2  3  0
one    5  6  7  4


>>> frame.sort_index(axis=1, ascending=False)		# 降序排列
       d  c  b  a
three  0  3  2  1
one    4  7  6  5



>>> obj=Series([4, 7, -3, 2])
>>> obj
0    4
1    7
2   -3
3    2
dtype: int64
>>> obj.order()						# Series排序需要用order
2   -3
3    2
0    4
1    7
dtype: int64
>>> obj.order(ascending=False)
1    7
0    4
3    2
2   -3
dtype: int64


>>> obj = Series([4, np.nan, 7, np.nan, -3, 2])		# 任何缺失值默认都会放到Series的末尾
>>> obj.order()						# 无论是Series还是DataFrame
4   -3.0
5    2.0
0    4.0
2    7.0
1    NaN
3    NaN
dtype: float64
>>> obj.order(ascending=False)
2    7.0
0    4.0
5    2.0
4   -3.0
1    NaN
3    NaN
dtype: float64


>>> frame=DataFrame({'b':[4, 7, -3, 2], 'a':[0,1,0,1]})
>>> frame
   a  b
0  0  4
1  1  7
2  0 -3
3  1  2
>>> frame.sort_index(by='b')	# 根据一个或多个列中的值进行排序。将一个或多个列的名字传递给by选项
   a  b
2  0 -3
3  1  2
0  0  4
1  1  7


>>> frame.sort_index(by=['b','a'])	# 先排b列 再排a列
   a  b
2  0 -3
3  1  2
0  0  4
1  1  7
>>> frame.sort_index(by=['a','b'])	# 先排a列 再排b列
   a  b
2  0 -3
0  0  4
3  1  2
1  1  7


排名（ranking）跟排序关系密切
>>> obj=Series([1,1,1,1,1,1])	# 从1开始，然后相同的数取平均数。
>>> obj.rank()
0    3.5
1    3.5
2    3.5
3    3.5
4    3.5
5    3.5
dtype: float64

>>> obj.rank()			# 从1开始，然后相同的数取平均数。
0    6.5
1    1.0
2    6.5
3    4.5
4    3.0
5    2.0
6    4.5
dtype: float64
>>> obj.rank(method='first')	#根据值在原数据中出现的顺序给出排名
0    6.0
1    1.0
2    7.0
3    4.0
4    3.0
5    2.0
6    5.0
dtype: float64
>>> obj.rank(ascending=False, method='max')	# 降序排名 max使用分组中的最大排名
0    2.0
1    7.0
2    2.0
3    4.0
4    5.0
5    6.0
6    4.0
dtype: float64

>>> frame= DataFrame({'b':[4.3, 7, -3, 2], 'a':[0, 1, 0, 1], 'c':[-2, 5, 8, -2.5]})
>>> frame
   a    b    c
0  0  4.3 -2.0
1  1  7.0  5.0
2  0 -3.0  8.0
3  1  2.0 -2.5
>>> frame.rank(axis=1)
     a    b    c
0  2.0  3.0  1.0
1  1.0  3.0  2.0
2  2.0  1.0  3.0
3  2.0  3.0  1.0


###带有重复值的轴索引###
>>> obj=Series(range(5), index=['a', 'a', 'b', 'b', 'c'])
>>> obj
a    0
a    1
b    2
b    3
c    4
dtype: int64
>>> obj.index.is_unique
False

>>> obj['a']		# 如果某个索引对应多个值，则返回一个Series
a    0
a    1
dtype: int64
>>> obj['c']		# 对应单个值，则返回一个标量值
4

>>> df = DataFrame(np.random.randn(4, 3), index=['a', 'a', 'b', 'b'])
>>> df
          0         1         2
a -0.761022  0.228550 -1.123073
a  0.668955 -1.197281 -0.328058
b -0.038427  2.159243  0.187048
b -0.588112  0.232811  0.859724
>>> df.ix['b']
          0         1         2
b -0.038427  2.159243  0.187048
b -0.588112  0.232811  0.859724


汇总和计算描述统计
>>> from pandas import DataFrame
>>> import numpy as np
>>> df=DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]],
... index=['a', 'b', 'c', 'd'], columns=['one', 'two'])
>>> df
    one  two
a  1.40  NaN
b  7.10 -4.5
c   NaN  NaN
d  0.75 -1.3
>>> df.sum()	# 按列进行求和
one    9.25
two   -5.80
dtype: float64
>>> df.sum(axis=1)	# 按行进行求和
a    1.40
b    2.60
c     NaN
d   -0.55
dtype: float64


>>> df
    one  two
a  1.40  NaN
b  7.10 -4.5
c   NaN  NaN
d  0.75 -1.3
>>> df.mean(axis=1, skipna=False)		# 禁止对于Na值的排除
a      NaN
b    1.300
c      NaN
d   -0.275
dtype: float64
>>> df.mean(axis=1)				# 
a    1.400
b    1.300
c      NaN
d   -0.275
dtype: float64


>>> df				# 返回间接统计（比如达到最小值或最大值的索引）
    one  two
a  1.40  NaN
b  7.10 -4.5
c   NaN  NaN
d  0.75 -1.3

>>> df.idxmax()
one    b
two    d
dtype: object

>>> df.idxmax()			# 累加
one    b
two    d
dtype: object
>>> df.cumsum()
    one  two
a  1.40  NaN
b  8.50 -4.5
c   NaN  NaN
d  9.25 -5.8


相关系数和协方差
>>> import pandas.io.data as web
>>> from pandas import Series
>>> from pandas import DataFrame
>>> all_data={}			# 创建一个空字典
>>> for ticker in ['AAPL', 'IBM']:
...     all_data[ticker]=web.get_data_yahoo(ticker, '1/1/2000', '1/10/2000')	# 从yahoofinance中提取AAPL和IBM的股票
>>> all_data									# all_data字典中key是'AAPL' 或'IBM' value是一个DataFrame的数据结构
{'AAPL':                   Open        High         Low       Close     Volume  \
Date
2000-01-03  104.874997  112.499998  101.687501  111.937502  133949200
2000-01-04  108.250001  110.625002  101.187503  102.500003  128094400
2000-01-05  103.749998  110.562497  103.000001  103.999997  194580400
2000-01-06  106.124999  106.999999   94.999998   94.999998  191993200
2000-01-07   96.499999  101.000002   95.500003   99.500001  115183600
2000-01-10  101.999998  102.249997   94.749999   97.750001  126266000

 Adj Close
Date
2000-01-03   3.641362
2000-01-04   3.334358
2000-01-05   3.383153
2000-01-06   3.090380
2000-01-07   3.236767

>>> price=DataFrame({tic:data['Adj Close'] for tic, data in all_data.iteritems()})	# iteritems 2.X python有itervalues()这一组函数 
>>> price										# 用于返回一个 iterator 
                AAPL        IBM
Date
2000-01-03  3.641362  88.455060
2000-01-04  3.334358  85.452544
2000-01-05  3.383153  88.455060
2000-01-06  3.090380  86.929973
2000-01-07  3.236767  86.548701
2000-01-10  3.179838  89.980147


>>> returns=price.pct_change()			# 计算百分数变化
>>> returns
                AAPL       IBM
Date
2000-01-03       NaN       NaN
2000-01-04 -0.084310 -0.033944
2000-01-05  0.014634  0.035137
2000-01-06 -0.086539 -0.017241
2000-01-07  0.047369 -0.004386
2000-01-10 -0.017588  0.039648
>>> price
                AAPL        IBM
Date
2000-01-03  3.641362  88.455060
2000-01-04  3.334358  85.452544
2000-01-05  3.383153  88.455060
2000-01-06  3.090380  86.929973
2000-01-07  3.236767  86.548701
2000-01-10  3.179838  89.980147
>>> returns.tail()				# 无NaN行
                AAPL       IBM
Date
2000-01-04 -0.084310 -0.033944
2000-01-05  0.014634  0.035137
2000-01-06 -0.086539 -0.017241
2000-01-07  0.047369 -0.004386
2000-01-10 -0.017588  0.039648


>>> returns.AAPL.std()
0.059513194146709428
>>> returns.IBM.std()
0.032409034043103566
>>> returns.AAPL.corr(returns.IBM)
0.57663870858430299
>>> returns.AAPL.cov(returns.IBM)
0.0011122006366748758
>>> returns.IBM.std()*returns.AAPL.std()*returns.AAPL.corr(returns.IBM)	# 两列数的协方差等于两个标准差乘以相关系数
0.0011122006366748756


>>> returns.corr()							# DataFrame的corr和cov返回完整的相关系数和协方差矩阵
          AAPL       IBM
AAPL  1.000000  0.576639
IBM   0.576639  1.000000
>>> returns.cov()
          AAPL       IBM
AAPL  0.003542  0.001112
IBM   0.001112  0.001050


>>> returns.corrwith(returns.IBM)					# corrwith可以计算一个DataFrame和另一个series和DataFrame之间的相关系数
AAPL    0.576639
IBM     1.000000
dtype: float64


唯一值、值计数以及成员资格
>>> obj=Series(['c','a','d','a','a','b','b','c','c'])	# 第一个函数是unique
>>> uniques=obj.unique()				# 它可以得到Series中的唯一值数组
>>> uniques
array(['c', 'a', 'd', 'b'], dtype=object)


>>> uniques = obj.unique()
>>> uniques
array(['c', 'a', 'd', 'b'], dtype=object)
>>> obj.value_counts()	# value_counts用于计算一个Series中各值出现的频率
c    3
a    3
b    2
d    1
dtype: int64


>>> mask=obj.isin(['b', 'c'])		# 用于判断矢量化集合的成员资格
>>> mask				# 可用于选取Series中或DataFrame列中数据的子集
0     True
1    False
2    False
3    False
4    False
5     True
6     True
7     True
8     True
dtype: bool
>>> obj[mask]
0    c
5    b
6    b
7    c
8    c
dtype: object


>>> data=DataFrame({'Qu1':[1, 3, 4, 3, 4],
... 'Qu2':[2, 3, 1, 2, 3],
... 'Qu3':[1, 5, 2, 4, 4]})
>>> data
   Qu1  Qu2  Qu3
0    1    2    1
1    3    3    5
2    4    1    2
3    3    2    4
4    4    3    4
>>> result=data.apply(pd.value_counts).fillna(0)	# 对data中的列apply pd.value_counts函数
>>> result
   Qu1  Qu2  Qu3
1  1.0  1.0  1.0
2  0.0  2.0  1.0
3  2.0  2.0  0.0
4  2.0  0.0  2.0
5  0.0  0.0  1.0

>>> result=data.apply(pd.value_counts, axis=1).fillna(0)
>>> result
     1    2    3    4    5
0  2.0  1.0  0.0  0.0  0.0
1  0.0  0.0  2.0  0.0  1.0
2  1.0  1.0  0.0  1.0  0.0
3  0.0  1.0  1.0  1.0  0.0
4  0.0  0.0  1.0  2.0  0.0


处理缺失数据
>>> string_data=Series(['aardvark', 'artichoke', np.nan, 'avocado'])		# NaN表示浮点和非浮点数组中的缺失数据
>>> string_data
0     aardvark
1    artichoke
2          NaN
3      avocado
dtype: object
>>> string_data.isnull()
0    False
1    False
2     True
3    False
dtype: bool
>>> string_data[0]=None
>>> string_data
0         None
1    artichoke
2          NaN
3      avocado
dtype: object
>>> string_data.isnull()
0     True
1    False
2     True
3    False
dtype: bool
>>>


滤除缺失数据
>>> from numpy import nan as NA
>>> data=Series([1, NA, 3.5, NA, 7])
>>> data.dropna()
0    1.0
2    3.5
4    7.0
dtype: float64

>>> data[data.notnull()]	# 也可以通过布尔型索引达到这个目的
0    1.0
2    3.5
4    7.0
dtype: float64


>>> data=DataFrame([[1.0, 6.5, 3.0], [1.0, NA, NA],
... [NA, NA, NA], [NA, 6.5, 3.0]])
>>> data
     0    1    2
0  1.0  6.5  3.0
1  1.0  NaN  NaN
2  NaN  NaN  NaN
3  NaN  6.5  3.0
>>> cleaned=data.dropna()		# dropna默认丢弃任何有缺失值的行
>>> cleaned
     0    1    2
0  1.0  6.5  3.0


>>> data.dropna(how='all')		# how=‘all’将只丢弃全为NA的那些行
     0    1    2
0  1.0  6.5  3.0
1  1.0  NaN  NaN
3  NaN  6.5  3.0


>>> data
     0    1    2   4
0  1.0  6.5  3.0 NaN
1  1.0  NaN  NaN NaN
2  NaN  NaN  NaN NaN
3  NaN  6.5  3.0 NaN
>>> data.dropna(axis=1,how='all')		# 丢弃整列都是NA值
     0    1    2
0  1.0  6.5  3.0
1  1.0  NaN  NaN
2  NaN  NaN  NaN
3  NaN  6.5  3.0


>>> df=DataFrame(np.random.randn(7,3))
>>> df.ix[:4, 1]=NA
>>> df.ix[:2, 2]=NA
>>> df
          0         1         2
0 -0.842856       NaN       NaN
1 -0.862389       NaN       NaN
2  1.149765       NaN       NaN
3  0.520349       NaN -1.481892
4 -1.130664       NaN -0.200879
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162
>>> df.dropna(thresh=3)		# 至少每行有三个非NA
          0         1         2
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162
>>> df.dropna(thresh=1)
          0         1         2
0 -0.842856       NaN       NaN
1 -0.862389       NaN       NaN
2  1.149765       NaN       NaN
3  0.520349       NaN -1.481892
4 -1.130664       NaN -0.200879
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162
>>> df.dropna(thresh=2)
          0         1         2
3  0.520349       NaN -1.481892
4 -1.130664       NaN -0.200879
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162


填充缺失数据
>>> df.fillna(0)
          0         1         2
0 -0.842856  0.000000  0.000000
1 -0.862389  0.000000  0.000000
2  1.149765  0.000000  0.000000
3  0.520349  0.000000 -1.481892
4 -1.130664  0.000000 -0.200879
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162

>>> df.fillna({1:0.5, 2:-1})		# 通过一个字典调用fillna，就可以实现对不同的列填充不同的值
          0         1         2
0 -0.842856  0.500000 -1.000000
1 -0.862389  0.500000 -1.000000
2  1.149765  0.500000 -1.000000
3  0.520349  0.500000 -1.481892
4 -1.130664  0.500000 -0.200879
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162

>>> _=df.fillna(0, inplace=True)		# fillna返回新对象，但也可以对现有对象进行就地修改
>>> df
          0         1         2
0 -0.842856  0.000000  0.000000
1 -0.862389  0.000000  0.000000
2  1.149765  0.000000  0.000000
3  0.520349  0.000000 -1.481892
4 -1.130664  0.000000 -0.200879
5  0.350709 -0.828031 -0.507767
6 -0.358415  0.606560  1.027162

>>> df = DataFrame(np.random.randn(6, 3))
>>> df.ix[2:, 1]=NA
>>> df.ix[4:, 2]=NA
>>> df
          0         1         2
0 -0.601720  0.868540  0.730089
1 -0.585113  1.390372  1.030539
2  1.208324       NaN  1.434392
3 -2.173415       NaN -0.340178
4 -0.028685       NaN       NaN
5  0.384403       NaN       NaN
>>> df.fillna(method='ffill')
          0         1         2
0 -0.601720  0.868540  0.730089
1 -0.585113  1.390372  1.030539
2  1.208324  1.390372  1.434392
3 -2.173415  1.390372 -0.340178
4 -0.028685  1.390372 -0.340178
5  0.384403  1.390372 -0.340178
>>> df.fillna(method='ffill', limit=2)
          0         1         2
0 -0.601720  0.868540  0.730089
1 -0.585113  1.390372  1.030539
2  1.208324  1.390372  1.434392
3 -2.173415  1.390372 -0.340178
4 -0.028685       NaN -0.340178
5  0.384403       NaN -0.340178

>>> data=Series([1.0, NA, 3.5, NA, 7])
>>> data.fillna(data.mean())
0    1.000000
1    3.833333
2    3.500000
3    3.833333
4    7.000000
dtype: float64


层次化索引

>>> import  numpy as np
>>> import pandas as pd
>>> from pandas import Series
>>> from pandas import DataFrame
>>> data=Series(np.random.randn(10),
... index=[['a','a','a','b','b','b','c','c','d','d'],
... [1,2,3,1,2,3,1,2,2,3]])
>>> data
a  1   -0.386136
   2   -1.933462
   3    1.564141
b  1   -0.031232
   2   -0.305060
   3    0.524174
c  1    3.111645
   2    0.247871
d  2    0.722982
   3   -0.256762
dtype: float64

>>> data.index
MultiIndex(levels=[[u'a', u'b', u'c', u'd'], [1, 2, 3]],
           labels=[[0, 0, 0, 1, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 1, 2, 0, 1, 1, 2]])


>>> data['b']		# 对于层次化索引对象，选取数据子集
1   -0.031232
2   -0.305060
3    0.524174
dtype: float64


>>> data['b':'c']
b  1   -0.031232
   2   -0.305060
   3    0.524174
c  1    3.111645
   2    0.247871
dtype: float64
>>> data.ix[['b','d']]
b  1   -0.031232
   2   -0.305060
   3    0.524174
d  2    0.722982
   3   -0.256762
dtype: float64
>>> data['b':'d']
b  1   -0.031232
   2   -0.305060
   3    0.524174
c  1    3.111645
   2    0.247871
d  2    0.722982
   3   -0.256762
dtype: float64

>>> data[:,2]		# 在“内层”中进行选取
a   -1.933462
b   -0.305060
c    0.247871
d    0.722982
dtype: float64


>>> data.unstack()		#通过unstack方法重新安排到一个DataFrame中
          1         2         3
a -0.386136 -1.933462  1.564141
b -0.031232 -0.305060  0.524174
c  3.111645  0.247871       NaN
d       NaN  0.722982 -0.256762


>>> data.unstack().stack()		# unstack的逆运算是stack
a  1   -0.386136
   2   -1.933462
   3    1.564141
b  1   -0.031232
   2   -0.305060
   3    0.524174
c  1    3.111645
   2    0.247871
d  2    0.722982
   3   -0.256762
dtype: float64


>>> frame=DataFrame(np.arange(12).reshape((4,3)),index=[['a','a','b','b'],[1, 2, 1, 2]],
... columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']])
>>> frame		# 一个DataFrame， 每条轴都可以有分层索引
     Ohio     Colorado
    Green Red    Green
a 1     0   1        2
  2     3   4        5
b 1     6   7        8
  2     9  10       11


>>> frame.index.names=['key1', 'key2']		# 索引名称
>>> frame.columns.names=['state', 'color']
>>> frame
state      Ohio     Colorado
color     Green Red    Green
key1 key2
a    1        0   1        2
     2        3   4        5
b    1        6   7        8
     2        9  10       11

>>> frame['Ohio']
color      Green  Red
key1 key2
a    1         0    1
     2         3    4
b    1         6    7
     2         9   10


###重排分级顺序###
>>> frame
state      Ohio     Colorado
color     Green Red    Green
key1 key2
a    1        0   1        2
     2        3   4        5
b    1        6   7        8
     2        9  10       11
>>> frame.swaplevel('key1', 'key2')	# swaplevel接受两个级别编号或名称，并返回一个
state      Ohio     Colorado		# 互换了级别的新对象（但数据不会发生变化）
color     Green Red    Green
key2 key1
1    a        0   1        2
2    a        3   4        5
1    b        6   7        8
2    b        9  10       11

swaplevel的应用
>>> frame1
state            Ohio            Colorado
color           Green       Red     Green
keys1 keys2
a     3     -0.026843 -0.557449  2.983456
      1     -0.303709  0.950943 -1.699359
      2      0.201512  0.610445  0.289560
c     1      0.690963  1.475376 -1.451312
b     1     -0.422497  0.284796 -0.990737

>>> frame1.swaplevel('keys1', 'keys2')
state            Ohio            Colorado
color           Green       Red     Green
keys2 keys1
3     a     -0.026843 -0.557449  2.983456
1     a     -0.303709  0.950943 -1.699359
2     a      0.201512  0.610445  0.289560
1     c      0.690963  1.475376 -1.451312
      b     -0.422497  0.284796 -0.990737

>>> frame1
state            Ohio            Colorado
color           Green       Red     Green
keys1 keys2
a     3     -0.026843 -0.557449  2.983456
      1     -0.303709  0.950943 -1.699359
      2      0.201512  0.610445  0.289560
c     1      0.690963  1.475376 -1.451312
b     1     -0.422497  0.284796 -0.990737

>>> frame1.sortlevel(0)				# sortlevel根据单个级别中的值对数据进行排序
state            Ohio            Colorado
color           Green       Red     Green
keys1 keys2
a     1     -0.303709  0.950943 -1.699359
      2      0.201512  0.610445  0.289560
      3     -0.026843 -0.557449  2.983456
b     1     -0.422497  0.284796 -0.990737
c     1      0.690963  1.475376 -1.451312

>>> frame1.sortlevel(1)
state            Ohio            Colorado
color           Green       Red     Green
keys1 keys2
a     1     -0.303709  0.950943 -1.699359
b     1     -0.422497  0.284796 -0.990737
c     1      0.690963  1.475376 -1.451312
a     2      0.201512  0.610445  0.289560
      3     -0.026843 -0.557449  2.983456

###根据级别汇总统计###

我们可以根据行或列上的级别来进行求和
>>> frame
state      Ohio     Colorado
color     Green Red    Green
key1 key2
a    1        0   1        2
     2        3   4        5
b    1        6   7        8
     2        9  10       11
>>> frame.sum(level='key2')	# 按行进行求和，按key2来求和，相同key2结合在一起
state  Ohio     Colorado
color Green Red    Green
key2
1         6   8       10
2        12  14       16
>>> frame.sum(level='color', axis=1)	# 按列中的color进行求和
color      Green  Red
key1 key2
a    1         2    1
     2         8    4
b    1        14    7
     2        20   10

###使用DataFrame的列###

人们经常想要将DataFrame的一个或者多个列当做行索引来用
或者可能希望将行索引变成DataFrame的列。

>>> frame=DataFrame({'a':range(7), 'b':range(7, 0, -1),
... 'c':['one', 'one', 'one', 'two', 'two', 'two', 'two'],
... 'd':[0, 1, 2, 0, 1, 2, 3]})
>>> frame
   a  b    c  d
0  0  7  one  0
1  1  6  one  1
2  2  5  one  2
3  3  4  two  0
4  4  3  two  1
5  5  2  two  2
6  6  1  two  3
>>> frame.loc[0:3]	# 行索引将
   a  b    c  d
0  0  7  one  0
1  1  6  one  1
2  2  5  one  2
3  3  4  two  0
>>> frame[0:2]		# 行索引
   a  b    c  d
0  0  7  one  0
1  1  6  one  1
>>> frame[['a','b']]	# 列索引
   a  b
0  0  7
1  1  6
2  2  5
3  3  4
4  4  3
5  5  2
6  6  1

>>> frame2=frame.set_index(['c', 'd'])		# set_index函数会将其一个或多个列转换为行索引，并创建一个新的DataFrame 
>>> frame2
       a  b
c   d
one 0  0  7
    1  1  6
    2  2  5
two 0  3  4
    1  4  3
    2  5  2
    3  6  1

>>> frame.set_index(['c', 'd'], drop=False)	# 那些列会从DataFrame中移除，但也可以将其保留
       a  b    c  d
c   d
one 0  0  7  one  0
    1  1  6  one  1
    2  2  5  one  2
two 0  3  4  two  0
    1  4  3  two  1
    2  5  2  two  2
    3  6  1  two  3

>>> frame2.reset_index()	# reset_index的功能跟set_index刚好相反，层次化
     c  d  a  b			# 索引的级别会被转移到列里面
0  one  0  0  7
1  one  1  1  6
2  one  2  2  5
3  two  0  3  4
4  two  1  4  3
5  two  2  5  2
6  two  3  6  1


###其他有关pandas的话题###

整数索引
>>> ser=Series(np.arange(3.))
>>> ser
0    0.0
1    1.0
2    2.0
dtype: float64
>>> ser[-1]	# 直接整数索引会有bug
KeyError: -1L
>>> ser2=Series(np.arange(3.), index=['a', 'b', 'c'])
>>> ser2[-1]
2.0

>>> ser.ix[::-1]		# 如果你的轴索引含有索引器 ix进行切片
2    2.0
1    1.0
0    0.0


>>> ser3=Series(range(3), index=[-5, 1, 3])
>>> ser3.iget_value(2)		# Series使用iget_value方法
2
>>> frame=DataFrame(np.arange(6).reshape(3, 2), index=[2, 0, 1])
>>> frame.irow(0)		# frame.irow返回的是一个Series
__main__:1: FutureWarning: irow(i) is deprecated. Please use .iloc[i]
0    0
1    1
Name: 2, dtype: int32
>>> frame.irow(0).icol(0)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "D:\python\pandas\core\generic.py", line 2672, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Series' object has no attribute 'icol'
>>> frame.irow(0).iget_value(0)		# 第一列第一行
0

###面板数据###
>>> pdata=pd.Panel(dict((stk, web.get_data_yahoo(stk, '1/1/2009', '6/1/2012'))		#Panel可以看做一个三维版的DataFrame
... for stk in ['AAPL', 'GOOG', 'MSFT', 'DELL']))
>>> pdata
<class 'pandas.core.panel.Panel'>
Dimensions: 4 (items) x 868 (major_axis) x 6 (minor_axis)
Items axis: AAPL to MSFT
Major_axis axis: 2009-01-02 00:00:00 to 2012-06-01 00:00:00
Minor_axis axis: Open to Adj Close

>>> pdata=pdata.swapaxes('items', 'minor')		# 两个坐标轴互换
>>> pdata
<class 'pandas.core.panel.Panel'>
Dimensions: 6 (items) x 868 (major_axis) x 4 (minor_axis)
Items axis: Open to Adj Close
Major_axis axis: 2009-01-02 00:00:00 to 2012-06-01 00:00:00
Minor_axis axis: AAPL to MSFT

>>> pdata.ix['Adj Close', '5/28/2012':'6/1/2012', :]	# 指定每个维度的值以及指定日期或日期范围
                 AAPL      DELL        GOOG       MSFT
Date
2012-05-28        NaN  12.05319         NaN        NaN
2012-05-29  74.464493  12.24666  296.873645  26.072491
2012-05-30  75.362333  12.14992  293.821674  25.878448
2012-05-31  75.174961  11.92743  290.140354  25.746145
2012-06-01  72.996726  11.67592  285.205295  25.093451

>>> stacked=pdata.ix[:,'5/30/2012':, :].to_frame()	# 通过to_frame形成堆积式的DataFrame
>>> stacked
                        Open        High         Low       Close       Volume  \
Date       minor
2012-05-30 AAPL   569.199997  579.989990  566.559990  579.169998  132357400.0
           DELL    12.590000   12.700000   12.460000   12.560000   19787800.0
           GOOG   588.161028  591.901014  583.530999  588.230992    3827600.0
           MSFT    29.350000   29.480000   29.120001   29.340000   41585500.0
2012-05-31 AAPL   580.740021  581.499985  571.460022  577.730019  122918600.0
           DELL    12.530000   12.540000   12.330000   12.330000   19955600.0
           GOOG   588.720982  590.001032  579.001013  580.860990    5958800.0
           MSFT    29.299999   29.420000   28.940001   29.190001   39134000.0
2012-06-01 AAPL   569.159996  572.650009  560.520012  560.989983  130246900.0
           DELL    12.150000   12.300000   12.045000   12.070000   19397600.0
           GOOG   571.790972  572.650996  568.350996  570.981000    6138700.0
           MSFT    28.760000   28.959999   28.440001   28.450001   56634300.0

                   Adj Close
Date       minor
2012-05-30 AAPL    75.362333
           DELL    12.149920
           GOOG   293.821674
           MSFT    25.878448
2012-05-31 AAPL    75.174961
           DELL    11.927430
           GOOG   290.140354
           MSFT    25.746145
2012-06-01 AAPL    72.996726
           DELL    11.675920
           GOOG   285.205295
           MSFT    25.093451

>>> stacked.to_panel()		# to_frame的逆运算
<class 'pandas.core.panel.Panel'>
Dimensions: 6 (items) x 3 (major_axis) x 4 (minor_axis)
Items axis: Open to Adj Close
Major_axis axis: 2012-05-30 00:00:00 to 2012-06-01 00:00:00
Minor_axis axis: AAPL to MSFT



########################################
########数据加载，存储与文件格式########
########################################

###读写文本格式的数据###
PS C:\Users\Weihong> type ex1.csv
a,b,c,d,message
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo

>>> df=pd.read_csv('ex1.csv')	# 用read_csv将其读入一个DataFrame
>>> df
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

>>> pd.read_table('ex1.csv', sep=',')	# 用read_table只不过需要指定分隔符
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo


>>> df=pd.read_csv('ex2.csv')		# 如果不设定，read_csv会把第一行默认是column name
>>> df
   1   2   3   4  hello
0  5   6   7   8  world
1  9  10  11  12    foo
>>> df=pd.read_csv('ex2.csv', header=None)	# 自动加 0 1 2.。。
>>> df
   0   1   2   3      4
0  1   2   3   4  hello
1  5   6   7   8  world
2  9  10  11  12    foo

>>> df=pd.read_csv('ex2.csv', names=['a', 'b', 'c', 'd', 'message'])	# 命名每列的名字
>>> df
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

>>> names=['a', 'b', 'c', 'd', 'message']
>>> pd.read_csv('ex2.csv', names=names, index_col='message')		# 希望将message列做成DataFrame的索引d
         a   b   c   d
message
hello    1   2   3   4
world    5   6   7   8
foo      9  10  11  12


>>> parsed=pd.read_csv('csv_mindex.csv', index_col=['key1', 'key2'])	# 将多个列做成一个层次化索引
>>> parsed								# 只需传入由列编号或列名组成的列表即可
           value1  value2
key1 key2
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  a          9      10
     b         11      12



	A	B	C		# 文件各个字段由数量不定的空白分隔符
aaa   -0.264  -1.026   -0.619		# 可以用正则表达式\s+表示
bbb    0.927   0.302    0.0323		
ccc    0.264   0.386   -0.217
ddd    -0.871  0.348    1.1004

>>> list(open('ex3.txt'))
['\tA\tB\tC\n', 'aaa   -0.264  -1.026   -0.619\n',
, 'ddd    -0.871  0.348    1.1004']
>>> result=pd.read_table('ex3.txt', sep='\s+')	#\s+表示一个或多个空白
>>> result					# 由于列名比数据行的数量少，所以read_table腿短第一列是DataFrame的索引
         A      B       C
aaa -0.264 -1.026 -0.6190
bbb  0.927  0.302  0.0323
ccc  0.264  0.386 -0.2170
ddd -0.871  0.348  1.1004


#hey
a,b,c,d,message
#just wanted 
#who reads CSV
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
>>> pd.read_csv('ex4.csv', skiprows=[0, 2, 3])		# 跳过文件的第一行、第三行和第四行
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo


>>> result=pd.read_csv('ex5.csv')
>>> result
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo
>>> result=pd.read_csv('ex5.csv', na_values=['NULL'])
>>> result
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

>>> result=pd.read_csv('ex5.csv', na_values=['one'])	# 指定某个值变成NaN
>>> result
  something  a   b     c   d message
0       NaN  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo


###逐块读取文本文件###
>>> result=pd.read_csv('ex6.csv', nrows=5)	# 通过nrows进行指定即可
>>> result
        one       two     three      four key
0  0.467976 -0.038649 -0.295344 -1.824726   L
1 -0.358893  1.404453  0.704965 -0.200638   B
2 -0.501840  0.659254 -0.421691 -0.057688   G
3  0.204886  1.074134  1.388361 -0.982404   R
4  0.354628 -0.133116  0.283763 -0.837063   Q


>>> chunker=pd.read_csv('ex6.csv', chunksize=1000)	# read_csv所返回的这个对象使我们可以根据chunksize对文件逐块迭代
>>> chunker
<pandas.io.parsers.TextFileReader object at 0x05637CF0>
>>> chunker=pd.read_csv('ex6.csv', chunksize=10)
>>> for piece in chunker:				# 每次读十行
...     print piece
...
        one       two     three      four key
0  0.467976 -0.038649 -0.295344 -1.824726   L
1 -0.358893  1.404453  0.704965 -0.200638   B
2 -0.501840  0.659254 -0.421691 -0.057688   G
3  0.204886  1.074134  1.388361 -0.982404   R
4  0.354628 -0.133116  0.283763 -0.837063   Q
5  1.817480  0.742273  0.419395 -2.251035   Q
6 -0.776764  0.935518 -0.332872 -1.875641   U
7 -0.913135  1.530624 -0.572657  0.477252   K
8  0.358480 -0.497572 -0.367016  0.507702   S
9 -1.740877 -1.160417 -1.637830  2.172201   G
        one       two     three      four key
0  0.240564 -0.328249  1.252155  1.072796   8
1  0.764018  1.165476 -0.639544  1.495258   R
2  0.571035 -0.310537  0.582437 -0.298765   1
3  2.317658  0.430710 -1.334216  0.199679   P
4  1.547771 -1.119753 -2.277634  0.329586   J
5 -1.310608  0.401719 -1.000987  1.156708   E
6 -0.088496  0.634712  0.153324  0.415335   B
7 -0.018663 -0.247487 -1.446522  0.750938   A
8 -0.070127 -1.579097  0.120892  0.671432   F
9 -0.194678 -0.492039  2.359605  0.319810   H

>>> tot=Series([])
>>> for piece in chunker:
...     tot=tot.add(piece['key'].value_counts(), fill_value=0)		#piece['key']得到的一个Series，因此可以用value_counts()
...
>>> tot=tot.order(ascending=False)
__main__:1: FutureWarning: order is deprecated, use sort_values(...)
>>> tot[:10]								#value_counts计数
E    368.0
X    364.0
L    346.0
O    343.0
Q    340.0
M    338.0
J    337.0
F    335.0
K    334.0
H    330.0
dtype: float64


###将数据写到文本格式###
>>> data=pd.read_csv('ex5.csv')
>>> data
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

>>> data.to_csv('out.csv')		# 我们将数据输出写到一个以逗号分隔的文件中

,something,a,b,c,d,message		# 缺失值会表示空字符串
0,one,1,2,3.0,4,
1,two,5,6,,8,world
2,three,9,10,11.0,12,foo

>>> data.to_csv(sys.stdout, sep='|')	#使用其他分隔符，这里直接写到sys.stdout
|something|a|b|c|d|message		# 所以仅仅是打印出文本结果而已
0|one|1|2|3.0|4|
1|two|5|6||8|world
2|three|9|10|11.0|12|foo


>>> data.to_csv(sys.stdout, na_rep=7)	# 可以将空字符表示为别的标记值
,something,a,b,c,d,message
0,one,1,2,3.0,4,7
1,two,5,6,7,8,world
2,three,9,10,11.0,12,foo

>>> data.to_csv(sys.stdout, index=False, header=False)	# 行和列的标签都可以被禁用
one,1,2,3.0,4,
two,5,6,,8,world
three,9,10,11.0,12,foo


>>> dates=pd.date_range('1/1/2000', periods=7)
>>> dates
DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04',
               '2000-01-05', '2000-01-06', '2000-01-07'],
              dtype='datetime64[ns]', freq='D')
>>> ts=Series(np.arange(7), index=dates)
>>> ts
2000-01-01    0
2000-01-02    1
2000-01-03    2
2000-01-04    3
2000-01-05    4
2000-01-06    5
2000-01-07    6
Freq: D, dtype: int32
>>> ts.to_csv('ts_series.csv')	# Series也有一个to_csv方法 输出的方法

ts_series.csv
2000-01-01,0
2000-01-02,1
2000-01-03,2
2000-01-04,3
2000-01-05,4
2000-01-06,5
2000-01-07,6

>>> Series.from_csv('ts_series.csv', parse_dates=True)		# 能用from_csv将CSV文件读取为Series
2000-01-01    0
2000-01-02    1
2000-01-03    2
2000-01-04    3
2000-01-05    4
2000-01-06    5
2000-01-07    6
dtype: int64


###手工处理分隔符格式###

>>> obj="""		# JSON数据
... {"name": "Wes",
... "places_lived":["United States", "Spain", "Germany"],
... "pet":null,
... "siblings":[{"name":"Scott", "age":25, "pet": "Zuko"},
... {"name":"Katie", "age":33, "pet":"Cisco"}]
... }
...
... """
>>> obj
'\n{"name": "Wes",\n"places_lived":["United States", "Spain", "Germany"],\n"pet":null,\n"sib
e":25, "pet": "Zuko"},\n{"name":"Katie", "age":33, "pet":"Cisco"}]\n}\n\n'
>>> import json
>>> result=json.loads(obj)
>>> result
{u'pet': None, u'siblings': [{u'pet': u'Zuko', u'age': 25, u'name': u'Scott'}, {u'pet': u'Ci
'Katie'}], u'name': u'Wes', u'places_lived': [u'United States', u'Spain', u'Germany']}
>>> asjson=json.dumps(result)		# python格式转为JSON格式

>>> siblings=DataFrame(result['siblings'])
>>> siblings
   age   name    pet
0   25  Scott   Zuko
1   33  Katie  Cisco


###XML和HTML:Web信息收集###
p185 有问题！！！！



###读取Microsoft Excel文件###
>>> xls_file=pd.ExcelFile('data.xlsx')		# 创建一个ExcelFile的实例
>>> xls_file
<pandas.io.excel.ExcelFile object at 0x0591DAF0>
>>> table=xls_file.parse('Sheet1')		# 通过parse读取到DataFrame中的数据，sheet表示表格形式1
>>> table
   1  2
0  3  4
1  5  6
2  7  8
>>> table=xls_file.parse()
>>> table
   1  2
0  3  4
1  5  6
2  7  8
>>> table=xls_file.parse('Sheet1', header=None)
>>> table
   0  1
0  1  2
1  3  4
2  5  6
3  7  8

>>> table=xls_file.parse('Sheet1', header=None)		# 如果没有会生成NaN
>>> table
     0  1    2
0  1.0  2  2.0
1  3.0  4  NaN
2  5.0  6  NaN
3  7.0  8  NaN
4  NaN  3  NaN
p192 这一章节没有好好看







##########################
#######数据规整化#########
#########################

###数据库风格的DataFrame合并###
>>> import pandas as pd
>>> from pandas import DataFrame
>>> df1=DataFrame({'key':['b', 'b', 'a', 'c', 'a', 'a', 'b'],
... 'data1':range(7)})
>>> df1
   data1 key
0      0   b
1      1   b
2      2   a
3      3   c
4      4   a
5      5   a
6      6   b
>>> df2=DataFrame({'key':['a', 'b', 'd'], 'data2':range(3)})
>>> df2
   data2 key
0      0   a
1      1   b
2      2   d

>>> df4=pd.merge(df1, df2)	# 多对一合并，如果没有指定，merge就会将重叠列的列名当做键
>>> df4				# 最好显示指定一下
   data1 key  data2
0      0   b      1
1      1   b      1
2      6   b      1
3      2   a      0
4      4   a      0
5      5   a      0

>>> pd.merge(df1, df2, on='key')
   data1 key  data2
0      0   b      1
1      1   b      1
2      6   b      1
3      2   a      0
4      4   a      0
5      5   a      0

>>> df4=DataFrame(df4, columns=['key', 'data1', 'data2'])	# 改变列的位置顺序
>>> df4
  key  data1  data2
0   b      0      1
1   b      1      1
2   b      6      1
3   a      2      0
4   a      4      0
5   a      5      0

>>> df4=DataFrame({'rkey':['a', 'b', 'd'], 'data2':range(3)})		# 两个对象的列名不同，也可以分别进行指定
>>> df3=DataFrame({'lkey':['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})	# 先指定那个元素，就先列出那个元素
>>> pd.merge(df3, df4, left_on='lkey', right_on='rkey')
   data1 lkey  data2 rkey
0      0    b      1    b
1      1    b      1    b
2      6    b      1    b
3      2    a      0    a
4      4    a      0    a
5      5    a      0    a
>>> pd.merge(df4, df3, left_on='rkey', right_on='lkey')
   data2 rkey  data1 lkey
0      0    a      2    a
1      0    a      4    a
2      0    a      5    a
3      1    b      0    b
4      1    b      1    b
5      1    b      6    b

>>> pd.merge(df1, df2, how='outer')	# 外连接求取的是键的并集
   data1 key  data2
0    0.0   b    1.0
1    1.0   b    1.0
2    6.0   b    1.0
3    2.0   a    0.0
4    4.0   a    0.0
5    5.0   a    0.0
6    3.0   c    NaN
7    NaN   d    2.0

>>> pd.merge(df4, df3, left_on='rkey', right_on='lkey', how='outer')
   data2 rkey  data1 lkey
0    0.0    a    2.0    a
1    0.0    a    4.0    a
2    0.0    a    5.0    a
3    1.0    b    0.0    b
4    1.0    b    1.0    b
5    1.0    b    6.0    b
6    2.0    d    NaN  NaN
7    NaN  NaN    3.0    c

多对多的合并操作
>>> df1=DataFrame({'key':['b', 'b', 'a', 'c', 'a', 'b'],
... 'data1':range(6)})
>>> df2=DataFrame({'key':['a', 'b', 'a', 'b', 'd'], 'data2':range(5)})
>>> df1
   data1 key
0      0   b
1      1   b
2      2   a
3      3   c
4      4   a
5      5   b
>>> df2
   data2 key
0      0   a
1      1   b
2      2   a
3      3   b
4      4   d

>>> pd.merge(df1, df2, on='key', how='left')	# 每种组会都排列出来
    data1 key  data2
0       0   b    1.0
1       0   b    3.0
2       1   b    1.0
3       1   b    3.0
4       2   a    0.0
5       2   a    2.0
6       3   c    NaN
7       4   a    0.0
8       4   a    2.0
9       5   b    1.0
10      5   b    3.0

###根据多个建进行合并###
>>> left=DataFrame({'key1':['foo', 'foo', 'bar'],
... 'key2':['one', 'two', 'one'],
... 'lval':[1, 2, 3]})
>>> right=DataFrame({'key1':['foo', 'foo', 'bar', 'bar'],
... 'key2':['one', 'one', 'one', 'two'],
... 'rval':[4, 5, 6, 7]})
>>> left
  key1 key2  lval
0  foo  one     1
1  foo  two     2
2  bar  one     3
>>> right
  key1 key2  rval
0  foo  one     4
1  foo  one     5
2  bar  one     6
3  bar  two     7
>>> pd.merge(left, right, on=['key1', 'key2'], how='outer')
  key1 key2  lval  rval
0  foo  one   1.0   4.0
1  foo  one   1.0   5.0
2  foo  two   2.0   NaN
3  bar  one   3.0   6.0
4  bar  two   NaN   7.0
>>> pd.merge(left, right, on=['key1'])
  key1 key2_x  lval key2_y  rval
0  foo    one     1    one     4
1  foo    one     1    one     5
2  foo    two     2    one     4
3  foo    two     2    one     5
4  bar    one     3    one     6
5  bar    one     3    two     7

>>> pd.merge(left, right, on=['key1'], suffixes=('_left', '_right'))	# 列名重叠后缀
  key1 key2_left  lval key2_right  rval
0  foo       one     1        one     4
1  foo       one     1        one     5
2  foo       two     2        one     4
3  foo       two     2        one     5
4  bar       one     3        one     6
5  bar       one     3        two     7


###索引上的合并###
>>> left1=DataFrame({'key':['a', 'b', 'a', 'a', 'b', 'c'], 'value':range(6)})
>>> right1=DataFrame({'group_val':[3.5, 7]}, index=['a', 'b'])
>>> left1
  key  value
0   a      0
1   b      1
2   a      2
3   a      3
4   b      4
5   c      5
>>> right1
   group_val
a        3.5
b        7.0
>>> pd.merge(left1, right1, left_on='key', right_index=True)
  key  value  group_val
0   a      0        3.5
2   a      2        3.5
3   a      3        3.5
1   b      1        7.0
4   b      4        7.0
>>> pd.merge(left1, right1, left_on='key', right_index=True, how='outer')	# 得到并集
  key  value  group_val
0   a      0        3.5
2   a      2        3.5
3   a      3        3.5
1   b      1        7.0
4   b      4        7.0
5   c      5        NaN

###层次化索引的数据###
>>> left=DataFrame({'key1':['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],
... 'key2':[2000, 2001, 2002, 2001, 2002],
... 'data':np.arange(5.)})
>>> righth=DataFrame(np.arange(12).reshape((6, 2)),
... index=[['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'],
... [2001, 2000, 2000, 2000, 2001, 2002]],
... columns=['event1', 'event2'])
>>> left
   data    key1  key2
0   0.0    Ohio  2000
1   1.0    Ohio  2001
2   2.0    Ohio  2002
3   3.0  Nevada  2001
4   4.0  Nevada  2002
>>> righth
             event1  event2
Nevada 2001       0       1
       2000       2       3
Ohio   2000       4       5
       2000       6       7
       2001       8       9
       2002      10      11
>>> pd.merge(left, righth, left_on=['key1', 'key2'], right_index=True)
   data    key1  key2  event1  event2
0   0.0    Ohio  2000       4       5
0   0.0    Ohio  2000       6       7
1   1.0    Ohio  2001       8       9
2   2.0    Ohio  2002      10      11
3   3.0  Nevada  2001       0       1

>>> pd.merge(left, righth, left_on=['key1', 'key2'], right_index=True, how='outer')
   data    key1    key2  event1  event2
0   0.0    Ohio  2000.0     4.0     5.0
0   0.0    Ohio  2000.0     6.0     7.0
1   1.0    Ohio  2001.0     8.0     9.0
2   2.0    Ohio  2002.0    10.0    11.0
3   3.0  Nevada  2001.0     0.0     1.0
4   4.0  Nevada  2002.0     NaN     NaN
4   NaN  Nevada  2000.0     2.0     3.0

###合并双方的索引###
>>> left2=DataFrame([[1, 2], [3, 4],[5, 6]], index=['a', 'c', 'e'],
... columns=['Ohio', 'Nevada'])
>>> right2=DataFrame([[7, 8], [9, 10], [11, 12],  [13, 14]],
... index=['b', 'c', 'd', 'e'], columns=['Missouri', 'Alabama'])
>>> left2
   Ohio  Nevada
a     1       2
c     3       4
e     5       6
>>> right2
   Missouri  Alabama
b         7        8
c         9       10
d        11       12
e        13       14
>>> pd.merge(left2, right2, how='outer', left_index=True, right_index=True)
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0

>>> left2.join(right2, how='outer')		# join实例方法
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0

>>> left1.join(right1, on='key')		# join支持DataFrame的某个列之间的链接
  key  value  group_val
0   a      0        3.5
1   b      1        7.0
2   a      2        3.5
3   a      3        3.5
4   b      4        7.0
5   c      5        NaN

>>> another=DataFrame([[7., 8.], [9. ,10.], [11., 12.], [16. ,17.]],
... index=['a', 'c', 'e', 'f'], columns=['New York', 'Oregon'])
>>> another
   New York  Oregon
a       7.0     8.0
c       9.0    10.0
e      11.0    12.0
f      16.0    17.0
>>> left2.join([right2, another])		# 还可以向join传入一组DataFrame
   Ohio  Nevada  Missouri  Alabama  New York  Oregon
a     1       2       NaN      NaN       7.0     8.0
c     3       4       9.0     10.0       9.0    10.0
e     5       6      13.0     14.0      11.0    12.0


###轴向连接###
>>> arr=np.array(np.arange(12).reshape(3,4))
>>> arr
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
>>> np.concatenate([arr, arr], axis=1)		# 行连接 Numpy合并
array([[ 0,  1,  2,  3,  0,  1,  2,  3],
       [ 4,  5,  6,  7,  4,  5,  6,  7],
       [ 8,  9, 10, 11,  8,  9, 10, 11]])
>>> np.concatenate([arr, arr], axis=0)		# 列连接
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

###DataFrame连接###
>>> s1=Series([0, 1], index=['a', 'b'])
>>> s2=Series([2, 3, 4], index=['c', 'd', 'e'])
>>> s3=Series([5, 6], index=['f', 'g'])
>>> pd.concat([s1, s2, s3])
a    0
b    1
c    2
d    3
e    4
f    5
g    6
dtype: int64
>>> s1
a    0
b    1
dtype: int64
>>> s2
c    2
d    3
e    4
dtype: int64
>>> s3
f    5
g    6
dtype: int64
>>> pd.concat([s1, s2, s3], axis=1)
     0    1    2
a  0.0  NaN  NaN
b  1.0  NaN  NaN
c  NaN  2.0  NaN
d  NaN  3.0  NaN
e  NaN  4.0  NaN
f  NaN  NaN  5.0
g  NaN  NaN  6.0

>>> s4=pd.concat([s1*5, s3])
>>> s4
a    0
b    5
f    5
g    6

>>> pd.concat([s1, s4], axis=1, join='inner')	# join='inner'即可得到它们的交集
   0  1
a  0  0
b  1  5

>>> pd.concat([s1, s4], axis=1, join_axes=[['a', 'c', 'b', 'f']])	# 通过join_axes指定要在其他轴上使用的索引
     0    1
a  0.0  0.0
c  NaN  NaN
b  1.0  5.0
f  NaN  5.0

>>> result=pd.concat([s1, s1, s3], keys=['one', 'two' ,'three'])
>>> result
one    a    0
       b    1
two    a    0
       b    1
three  f    5
       g    6
dtype: int64


>>> result=pd.concat([s1, s1, s3], keys=['one', 'two' ,'three'])	# 假设你想要在连接轴上创建一个层次化
>>> result								# 将参与连接的片段在结果中区分开
one    a    0
       b    1
two    a    0
       b    1
three  f    5
       g    6
dtype: int64
>>> result.unstack()		# unstack函数
         a    b    f    g
one    0.0  1.0  NaN  NaN
two    0.0  1.0  NaN  NaN
three  NaN  NaN  5.0  6.0

>>> pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three'])	# 沿着axis=1对Series进行合并
   one  two  three							# 则keys就会成为DataFrame的列头
a  0.0  NaN    NaN
b  1.0  NaN    NaN
c  NaN  2.0    NaN
d  NaN  3.0    NaN
e  NaN  4.0    NaN
f  NaN  NaN    5.0
g  NaN  NaN    6.0


>>> df1=DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'],
... columns=['one', 'two'])
>>> df2=DataFrame(5+np.arange(4).reshape(2,2), index=['a','c'],
... columns=['three', 'four'])
>>> df1
   one  two
a    0    1
b    2    3
c    4    5
>>> df2
   three  four
a      5     6
c      7     8
>>> pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])	#
  level1     level2
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0

>>> pd.concat({'level1':df1, 'level2':df2}, axis=1)		# 传入的不是列表而是一个字典
  level1     level2						# 则字典的键就会被当做keys选项的值
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0

>>> pd.concat([df1, df2], axis=1, keys=['level1', 'level2'], names=['upper', 'lower'])	# 管理层次化索引创建方式的参数
upper level1     level2
lower    one two  three four
a          0   1    5.0  6.0
b          2   3    NaN  NaN
c          4   5    7.0  8.0


>>> df1=DataFrame(np.random.randn(3,4), columns=['a', 'b', 'c', 'd'])
>>> df2=DataFrame(np.random.randn(2,3), columns=['b', 'd', 'a'])
>>> df1
          a         b         c         d
0  0.425610 -0.301489  1.098388  1.082600
1 -0.526522  0.443978 -0.620161 -0.432289
2  0.287441 -0.479613  0.214522  0.036117
>>> df2
          b         d         a
0  0.535586  1.977750  1.278601
1 -0.508055 -0.111801  0.086542
>>> pd.concat([df1, df2])
          a         b         c         d
0  0.425610 -0.301489  1.098388  1.082600
1 -0.526522  0.443978 -0.620161 -0.432289
2  0.287441 -0.479613  0.214522  0.036117
0  1.278601  0.535586       NaN  1.977750
1  0.086542 -0.508055       NaN -0.111801
>>> pd.concat([df1, df2], ignore_index=True)	# 处理与当前工作无关的DataFrame行索引
          a         b         c         d
0  0.425610 -0.301489  1.098388  1.082600
1 -0.526522  0.443978 -0.620161 -0.432289
2  0.287441 -0.479613  0.214522  0.036117
3  1.278601  0.535586       NaN  1.977750
4  0.086542 -0.508055       NaN -0.111801

###合并重叠数据###

>>> a=Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan], index=['f', 'e', 'd', 'c', 'b', 'a'])
>>> a
f    NaN
e    2.5
d    NaN
c    3.5
b    4.5
a    NaN
dtype: float64

>>> b=Series(np.arange(len(a), dtype=np.float64), index=['f', 'e', 'd', 'c', 'b', 'a'])
>>> b
f    0.0
e    1.0
d    2.0
c    3.0
b    4.0
a    5.0
dtype: float64

>>> b[-1]=np.nan
>>> b
f    0.0
e    1.0
d    2.0
c    3.0
b    4.0
a    NaN
dtype: float64

>>> np.where(pd.isnull(a), b, a)	# 如果pd.isnull()是nan 则输出b中的数，否则输出a中的数
array([ 0. ,  2.5,  2. ,  3.5,  4.5,  nan])

>>> b[:-2].combine_first(a[2:])		# b[:-2]中没有，则用a[2:]中的数值
a    NaN
b    4.5
c    3.0
d    2.0
e    1.0
f    0.0
dtype: float64

>>> a.combine_first(b)
f    0.0
e    2.5
d    2.0
c    3.5
b    4.5
a    NaN
dtype: float64

>>> df1=DataFrame({'a':[1, np.nan, 5., np.nan],
... 'b':[np.nan, 2., np.nan, 6.],
... 'c':range(2, 18, 4)})
>>> df2=DataFrame({'a':[5., 4., np.nan, 3., 7.],
... 'b':[np.nan, 3., 4., 6., 8.]})
>>> df1
     a    b   c
0  1.0  NaN   2
1  NaN  2.0   6
2  5.0  NaN  10
3  NaN  6.0  14
>>> df2
     a    b
0  5.0  NaN
1  4.0  3.0
2  NaN  4.0
3  3.0  6.0
4  7.0  8.0
>>> df1.combine_first(df2)	# 用参数对象中的数据为调用者对象的缺失数据“打补丁”
     a    b     c
0  1.0  NaN   2.0
1  4.0  2.0   6.0
2  5.0  4.0  10.0
3  3.0  6.0  14.0
4  7.0  8.0   NaN

###重塑和轴向旋转###

###重塑层次化索引###
>>> from pandas import DataFrame
>>> data=DataFrame(np.arange(6).reshape((2,3)), index=pd.Index(['Ohio', 'Colorado'], name='state'), columns=pd.Index(['
ne', 'two', 'three'], name='number'))
>>> data
number    one  two  three
state
Ohio        0    1      2
Colorado    3    4      5
>>> result=data.stack()		# 使用该数据的stack方法即可将列转换为行，得到一个Series
>>> result
state     number
Ohio      one       0
          two       1
          three     2
Colorado  one       3
          two       4
          three     5
dtype: int32
>>> result.unstack()
number    one  two  three	# 对于一个层次化索引的Series
state				# 可以用unstack将其重排为一个DataFrame
Ohio        0    1      2
Colorado    3    4      5

>>> result.unstack(1)		# 默认情况下，unstack操作的是最内层
number    one  two  three	# unstack（1）操作最内层
state
Ohio        0    1      2
Colorado    3    4      5
>>> result.unstack(0)		# 外层
state   Ohio  Colorado
number
one        0         3
two        1         4
three      2         5

>>> s1=Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])
>>> s2=Series([4, 5, 6], index=['c', 'd', 'e'])
>>> data2=pd.concat([s1, s2], keys=['one', 'two'])
>>> data2
one  a    0
     b    1
     c    2
     d    3
two  c    4
     d    5
     e    6
dtype: int64
>>> data2.unstack()	# unstack操作可能会引入缺失数据
       a    b    c    d    e
one  0.0  1.0  2.0  3.0  NaN
two  NaN  NaN  4.0  5.0  6.0

>>> data2.unstack().stack()	#stack默认会滤除缺失数据，因此该运算时可逆的
one  a    0.0
     b    1.0
     c    2.0
     d    3.0
two  c    4.0
     d    5.0
     e    6.0
dtype: float64

>>> data2.unstack().stack(dropna=False)
one  a    0.0
     b    1.0
     c    2.0
     d    3.0
     e    NaN
two  a    NaN
     b    NaN
     c    4.0
     d    5.0
     e    6.0
dtype: float64

>>> df=DataFrame({'left':result, 'right':result+5}, columns=pd.Index(['left', 'right'], name='side'))
>>> df
side             left  right
state    number
Ohio     one        0      5
         two        1      6
         three      2      7
Colorado one        3      8
         two        4      9
         three      5     10
>>> df.unstack('state')		# 旋转轴的级别将会是结果中的最低级别
side   left          right
state  Ohio Colorado  Ohio Colorado
number
one       0        3     5        8
two       1        4     6        9
three     2        5     7       10

>>> df.unstack('state').stack('side')
state         Ohio  Colorado
number side
one    left      0         3
       right     5         8
two    left      1         4
       right     6         9
three  left      2         5
       right     7        10























####数据处理####

###从网络获得数据###
>>> import pandas as pd
>>> from pandas import DataFrame
>>> from pandas import Series
>>> data_url = "https://raw.githubusercontent.com/alstat/Analysis-with-Programming/master/2014/Python/Numerical-Descript
ions-of-the-Data/data.csv"
>>> df=pd.read_csv(data_url)
>>> df


>>> print df.head()	# head of data 默认5行
    Abra  Apayao  Benguet  Ifugao  Kalinga
0   1243    2934      148    3300    10553
1   4158    9235     4287    8063    35257
2   1787    1922     1955    1074     4544
3  17152   14501     3536   19607    31687
4   1266    2385     2530    3315     8520
>>> print df.head(4)
    Abra  Apayao  Benguet  Ifugao  Kalinga
0   1243    2934      148    3300    10553
1   4158    9235     4287    8063    35257
2   1787    1922     1955    1074     4544
3  17152   14501     3536   19607    31687

>>> print df.tail(7)	# tail of the data
     Abra  Apayao  Benguet  Ifugao  Kalinga
72   6209    6335     3530   15560    24385
73  13316   38613     2585    7746    66148
74   2505   20878     3519   19737    16513
75  60303   40065     7062   19422    61808
76   6311    6756     3561   15910    23349
77  13345   38902     2583   11096    68663
78   2623   18264     3745   16787    16900


>>> print df.columns	# extract columns name
Index([u'Abra', u'Apayao', u'Benguet', u'Ifugao', u'Kalinga'], dtype='object')
>>> print df.index	# extract index name
RangeIndex(start=0, stop=79, step=1)

###打印第一列的前5行
>>> print df.ix[:, 0].head()
0     1243
1     4158
2     1787
3    17152
4     1266
Name: Abra, dtype: int64


>>> print df.ix[10:20, 0:3]	# 为了取出从11到20行的前3列数据
     Abra  Apayao  Benguet
10    981    1311     2560
11  27366   15093     3039
12   1100    1701     2382
13   7212   11001     1088
14   1048    1427     2847
15  25679   15661     2942
16   1055    2191     2119
17   5437    6461      734
18   1029    1183     2302
19  23710   12222     2598
20   1091    2343     2654


>>> print df.describe()		# 通过describe属性，对数据的统计特性进行描述
               Abra        Apayao      Benguet        Ifugao       Kalinga
count     79.000000     79.000000    79.000000     79.000000     79.000000
mean   12874.379747  16860.645570  3237.392405  12414.620253  30446.417722
std    16746.466945  15448.153794  1588.536429   5034.282019  22245.707692
min      927.000000    401.000000   148.000000   1074.000000   2346.000000
25%     1524.000000   3435.500000  2328.000000   8205.000000   8601.500000
50%     5790.000000  10588.000000  3202.000000  13044.000000  24494.000000
75%    13330.500000  33289.000000  3918.500000  16099.500000  52510.500000
max    60303.000000  54625.000000  8813.000000  21031.000000  68663.000000

>>> from scipy import stats as ss
>>> print ss.ttest_1samp(a=df.ix[:, 'Abra'], popmean=15000)
Ttest_1sampResult(statistic=-1.1281738488299586, pvalue=0.26270472069109496)
看到p值是0.267远大于α等于0.05 拒绝H0









###数据可视化###

水平bar图
PS C:\Users\Weihong> cat pyplot_1.py
"""
Simple demo of a horizontal bar chart.
"""

import matplotlib.pyplot as plt
from matplotlib import cm
import numpy as np

# Example data
#cols = ['blue', 'green', 'red', 'cyan', 'yellow']	# 可以通过颜色列表的方式给每个bar添加颜色
people=('Tom', 'Dick','Harry', 'Slim', 'Jim')
y_pos=np.arange(len(people))	
#y_pos=np.arange(1,6)
performance=3+10*np.random.rand(len(people))
color=cm.jet(performance/max(performance))		# 也可以通过colormap来给bar添加颜色
error=np.random.rand(len(people))

#plt.barh(y_pos, performance, xerr=error, align='center', alpha=0.4)
plt.barh(y_pos, performance, xerr=error, linewidth=0, color=color, ecolor='red', align='center', alpha=0.4)	# xerr表示误差 alpha表示透明度
plt.yticks(y_pos, people)				# y轴上的命名
plt.xlabel('Performance')
plt.title('How fast do you want to go today?')

plt.show()









